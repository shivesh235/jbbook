
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Generative Models &#8212; Shivesh Singh</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'genai/Generation_using_VAE's_and_GAN's';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Database" href="../Databases.html" />
    <link rel="prev" title="Education &amp; Experiences" href="../experiences.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Shivesh Singh</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../experiences.html">Education &amp; Experiences</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Generative Models</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Databases.html">Database</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Dashboard.html">Interactive Dashboard Creation with Streamlit</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/shivesh235/jbbook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/shivesh235/jbbook/issues/new?title=Issue%20on%20page%20%2Fgenai/Generation_using_VAE's_and_GAN's.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/genai/Generation_using_VAE's_and_GAN's.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Generative Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Generative Models</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-vae-on-mnist-dataset">Implement VAE on MNIST dataset</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#programming-use-pytorch-tf-library">2 Programming - Use Pytorch/TF library</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-autoencoder">2.1 Variational Autoencoder</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-basic-vae-on-celeba-faces-dataset">1. Implement basic VAE on celebA faces dataset.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#latent-space-arithmetic-make-your-image-smile-generate-smiling-face-images-by-playing-with-latent-space-z-vector">2. Latent Space arithmetic - Make your image smile. Generate smiling face images by playing with latent space z vector.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variants-of-gans">2.2 Variants of GANs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-a-standard-gan-on-mnist-cifar-10-data-plot-generator-loss-discriminator-loss-and-classification-accuracy-of-discriminator-with-respect-to-iterations">1. Implement a standard GAN on MNIST/CIFAR-10 data. Plot Generator loss, Discriminator Loss and Classification accuracy of discriminator with respect to iterations.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstrate-the-vanishing-gradient-problem-of-standard-gan-by-training-your-gan-for-5-10-and-25-epochs-then-stop-the-gan-training-train-only-the-discriminator-till-it-reaches-100-accuracy-and-then-use-this-perfect-discriminator-to-train-your-gan-plot-the-generator-loss-gradient-norm-and-discriminator-loss-w-r-t-epochs-using-your-perfect-discriminator">2. Demonstrate the vanishing gradient problem of standard GAN by training your GAN for 5,10 and 25 epochs. Then stop the GAN training, train only the discriminator till it reaches 100% accuracy and then use this perfect discriminator to train your GAN. Plot the generator loss/gradient norm and discriminator loss w.r.t epochs (using your perfect discriminator).</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-wgan-with-weight-clipping-strategy-and-wgan-gp-gradient-penalty-with-cifar-10-dataset-plot-the-generator-loss-and-discriminator-loss-w-r-t-epochs">3. Implement WGAN (with weight clipping strategy) and WGAN-GP (Gradient penalty) with Cifar-10 dataset. Plot the generator loss and discriminator loss w.r.t epochs.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-sngan-framework-too-with-cifar-10-dataset">4. Implement SNGAN framework too with Cifar-10 dataset.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#observe-and-compare-the-time-complexity-of-sn-gan-and-wgan-gp">5. Observe and Compare the time complexity of SN-GAN and WGAN-GP.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-inception-score-and-fid-scores-to-evaluate-models-trained-in-previous-questions">6. Use Inception score and FID scores to evaluate models trained in previous questions.</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="generative-models">
<h1>Generative Models<a class="headerlink" href="#generative-models" title="Link to this heading">#</a></h1>
<section id="implement-vae-on-mnist-dataset">
<h2>Implement VAE on MNIST dataset<a class="headerlink" href="#implement-vae-on-mnist-dataset" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Hyperparameters</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2048</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">20</span> 
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">img_size</span> <span class="o">=</span> <span class="mi">28</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
<span class="p">])</span>

<span class="k">class</span> <span class="nc">VAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VAE</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>  <span class="c1"># 256x4x4 output</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># Assuming the flattened encoder output is (256 * 4 * 4) = 4096</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_logvar</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>

        <span class="c1"># Decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_dec</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Unflatten</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>                       
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Encoding</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
        <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_logvar</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>

        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>

        <span class="c1"># Decoding</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_dec</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">decoded</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">decoded</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
    <span class="n">BCE</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="n">recon_x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">KLD</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">logvar</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span> <span class="o">/</span> <span class="n">recon_x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">BCE</span> <span class="o">+</span> <span class="n">KLD</span>

<span class="c1"># Load MNIST dataset</span>
<span class="n">mnist_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./mnist&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">mnist_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Training loop</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">recon_batch</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">recon_batch</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">epoch</span><span class="o">%</span><span class="k">20</span> == 0:
      <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">, Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
      <span class="c1"># Save model</span>
      <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="s1">&#39;vae_mnist_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">.pth&#39;</span><span class="p">)</span>

<span class="c1"># Generate samples</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">generated</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc_dec</span><span class="p">(</span><span class="n">sample</span><span class="p">))</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

<span class="c1"># Save generated images</span>
<span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">save_image</span><span class="p">(</span><span class="n">generated</span><span class="p">,</span> <span class="s1">&#39;vae_mnist_samples.png&#39;</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training complete. Generated samples saved as &#39;vae_mnist_samples.png&#39;.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Failed to download (trying next):
HTTP Error 403: Forbidden

Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "a1f82860c60e4b76a4cfc6f76423061d"}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Failed to download (trying next):
HTTP Error 403: Forbidden

Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "7296589290d246efb676d3c2d5b08659"}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Failed to download (trying next):
HTTP Error 403: Forbidden

Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "b573e3fd4c6644e683bfa6193eb36b27"}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">89</span>
<span class="g g-Whitespace">     </span><span class="mi">86</span>     <span class="k">return</span> <span class="n">BCE</span> <span class="o">+</span> <span class="n">KLD</span>
<span class="g g-Whitespace">     </span><span class="mi">88</span> <span class="c1"># Load MNIST dataset</span>
<span class="ne">---&gt; </span><span class="mi">89</span> <span class="n">mnist_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./mnist&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">90</span> <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">mnist_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">92</span> <span class="c1"># Training loop</span>

<span class="nn">File ~/miniconda3/envs/env1/lib/python3.10/site-packages/torchvision/datasets/mnist.py:99,</span> in <span class="ni">MNIST.__init__</span><span class="nt">(self, root, train, transform, target_transform, download)</span>
<span class="g g-Whitespace">     </span><span class="mi">96</span>     <span class="k">return</span>
<span class="g g-Whitespace">     </span><span class="mi">98</span> <span class="k">if</span> <span class="n">download</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">99</span>     <span class="bp">self</span><span class="o">.</span><span class="n">download</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">101</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_exists</span><span class="p">():</span>
<span class="g g-Whitespace">    </span><span class="mi">102</span>     <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Dataset not found. You can use download=True to download it&quot;</span><span class="p">)</span>

<span class="nn">File ~/miniconda3/envs/env1/lib/python3.10/site-packages/torchvision/datasets/mnist.py:187,</span> in <span class="ni">MNIST.download</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">185</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">186</span>     <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Downloading </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">187</span>     <span class="n">download_and_extract_archive</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">download_root</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_folder</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span> <span class="n">md5</span><span class="o">=</span><span class="n">md5</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">188</span> <span class="k">except</span> <span class="n">URLError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">189</span>     <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to download (trying next):</span><span class="se">\n</span><span class="si">{</span><span class="n">error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nn">File ~/miniconda3/envs/env1/lib/python3.10/site-packages/torchvision/datasets/utils.py:446,</span> in <span class="ni">download_and_extract_archive</span><span class="nt">(url, download_root, extract_root, filename, md5, remove_finished)</span>
<span class="g g-Whitespace">    </span><span class="mi">443</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">filename</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">444</span>     <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">446</span> <span class="n">download_url</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">download_root</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">md5</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">448</span> <span class="n">archive</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">download_root</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">449</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Extracting </span><span class="si">{</span><span class="n">archive</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">extract_root</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nn">File ~/miniconda3/envs/env1/lib/python3.10/site-packages/torchvision/datasets/utils.py:156,</span> in <span class="ni">download_url</span><span class="nt">(url, root, filename, md5, max_redirect_hops)</span>
<span class="g g-Whitespace">    </span><span class="mi">154</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">155</span>     <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Downloading &quot;</span> <span class="o">+</span> <span class="n">url</span> <span class="o">+</span> <span class="s2">&quot; to &quot;</span> <span class="o">+</span> <span class="n">fpath</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">156</span>     <span class="n">_urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">fpath</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">157</span> <span class="k">except</span> <span class="p">(</span><span class="n">urllib</span><span class="o">.</span><span class="n">error</span><span class="o">.</span><span class="n">URLError</span><span class="p">,</span> <span class="ne">OSError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>  <span class="c1"># type: ignore[attr-defined]</span>
<span class="g g-Whitespace">    </span><span class="mi">158</span>     <span class="k">if</span> <span class="n">url</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;https&quot;</span><span class="p">:</span>

<span class="nn">File ~/miniconda3/envs/env1/lib/python3.10/site-packages/torchvision/datasets/utils.py:50,</span> in <span class="ni">_urlretrieve</span><span class="nt">(url, filename, chunk_size)</span>
<span class="g g-Whitespace">     </span><span class="mi">48</span> <span class="k">def</span> <span class="nf">_urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">32</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">49</span>     <span class="k">with</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;User-Agent&quot;</span><span class="p">:</span> <span class="n">USER_AGENT</span><span class="p">}))</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">50</span>         <span class="n">_save_response_content</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">),</span> <span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">),</span> <span class="n">filename</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">length</span><span class="p">)</span>

<span class="nn">File ~/miniconda3/envs/env1/lib/python3.10/site-packages/torchvision/datasets/utils.py:39,</span> in <span class="ni">_save_response_content</span><span class="nt">(content, destination, length)</span>
<span class="g g-Whitespace">     </span><span class="mi">33</span> <span class="k">def</span> <span class="nf">_save_response_content</span><span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">34</span>     <span class="n">content</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">[</span><span class="nb">bytes</span><span class="p">],</span>
<span class="g g-Whitespace">     </span><span class="mi">35</span>     <span class="n">destination</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">36</span>     <span class="n">length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">37</span> <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">38</span>     <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">destination</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fh</span><span class="p">,</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">length</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">39</span>         <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">content</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">40</span>             <span class="c1"># filter out keep-alive new chunks</span>
<span class="g g-Whitespace">     </span><span class="mi">41</span>             <span class="k">if</span> <span class="ow">not</span> <span class="n">chunk</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">42</span>                 <span class="k">continue</span>

<span class="nn">File ~/miniconda3/envs/env1/lib/python3.10/site-packages/torchvision/datasets/utils.py:50,</span> in <span class="ni">_urlretrieve.&lt;locals&gt;.&lt;lambda&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">     </span><span class="mi">48</span> <span class="k">def</span> <span class="nf">_urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">32</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">49</span>     <span class="k">with</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;User-Agent&quot;</span><span class="p">:</span> <span class="n">USER_AGENT</span><span class="p">}))</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">50</span>         <span class="n">_save_response_content</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">),</span> <span class="sa">b</span><span class="s2">&quot;&quot;</span><span class="p">),</span> <span class="n">filename</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">length</span><span class="p">)</span>

<span class="nn">File ~/miniconda3/envs/env1/lib/python3.10/http/client.py:466,</span> in <span class="ni">HTTPResponse.read</span><span class="nt">(self, amt)</span>
<span class="g g-Whitespace">    </span><span class="mi">463</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">amt</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">length</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">464</span>     <span class="c1"># clip the read to the &quot;end of response&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">465</span>     <span class="n">amt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">length</span>
<span class="ne">--&gt; </span><span class="mi">466</span> <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fp</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">amt</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">467</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">s</span> <span class="ow">and</span> <span class="n">amt</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">468</span>     <span class="c1"># Ideally, we would raise IncompleteRead if the content-length</span>
<span class="g g-Whitespace">    </span><span class="mi">469</span>     <span class="c1"># wasn&#39;t satisfied, but it might break compatibility.</span>
<span class="g g-Whitespace">    </span><span class="mi">470</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_close_conn</span><span class="p">()</span>

<span class="nn">File ~/miniconda3/envs/env1/lib/python3.10/socket.py:705,</span> in <span class="ni">SocketIO.readinto</span><span class="nt">(self, b)</span>
<span class="g g-Whitespace">    </span><span class="mi">703</span> <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">704</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">705</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sock</span><span class="o">.</span><span class="n">recv_into</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">706</span>     <span class="k">except</span> <span class="n">timeout</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">707</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_timeout_occurred</span> <span class="o">=</span> <span class="kc">True</span>

<span class="nn">File ~/miniconda3/envs/env1/lib/python3.10/ssl.py:1307,</span> in <span class="ni">SSLSocket.recv_into</span><span class="nt">(self, buffer, nbytes, flags)</span>
<span class="g g-Whitespace">   </span><span class="mi">1303</span>     <span class="k">if</span> <span class="n">flags</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1304</span>         <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1305</span>           <span class="s2">&quot;non-zero flags not allowed in calls to recv_into() on </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span>
<span class="g g-Whitespace">   </span><span class="mi">1306</span>           <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1307</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">nbytes</span><span class="p">,</span> <span class="n">buffer</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1308</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1309</span>     <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">recv_into</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">nbytes</span><span class="p">,</span> <span class="n">flags</span><span class="p">)</span>

<span class="nn">File ~/miniconda3/envs/env1/lib/python3.10/ssl.py:1163,</span> in <span class="ni">SSLSocket.read</span><span class="nt">(self, len, buffer)</span>
<span class="g g-Whitespace">   </span><span class="mi">1161</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1162</span>     <span class="k">if</span> <span class="n">buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1163</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sslobj</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span> <span class="n">buffer</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1164</span>     <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1165</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sslobj</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="nb">len</span><span class="p">)</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;vae_mnist_samples.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1608be7570eb60a1b32005f2bc91e7163514580ed72d84dc8e70fc7f399f4ee3.png" src="../_images/1608be7570eb60a1b32005f2bc91e7163514580ed72d84dc8e70fc7f399f4ee3.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="programming-use-pytorch-tf-library">
<h1>2 Programming - Use Pytorch/TF library<a class="headerlink" href="#programming-use-pytorch-tf-library" title="Link to this heading">#</a></h1>
<section id="variational-autoencoder">
<h2>2.1 Variational Autoencoder<a class="headerlink" href="#variational-autoencoder" title="Link to this heading">#</a></h2>
<section id="implement-basic-vae-on-celeba-faces-dataset">
<h3>1. Implement basic VAE on celebA faces dataset.<a class="headerlink" href="#implement-basic-vae-on-celeba-faces-dataset" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">zipfile</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Hyperparameters</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">img_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">img_size</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># VAE Model</span>
<span class="k">class</span> <span class="nc">VAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VAE</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_logvar</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>

        <span class="c1"># Decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_input</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">256</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span><span class="p">(</span><span class="n">h</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_logvar</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_input</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span>


<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="c1"># model.load_state_dict(torch.load(&#39;vae_celeba.pth&#39;))</span>

<span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
    <span class="n">BCE</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="n">recon_x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Normalizing the loss</span>
    <span class="n">KLD</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">logvar</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">BCE</span> <span class="o">+</span> <span class="n">KLD</span>

<span class="k">class</span> <span class="nc">CelebADataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_dir</span><span class="p">,</span> <span class="n">partition_file</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">partition</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">img_dir</span> <span class="o">=</span> <span class="n">img_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">partition_file</span> <span class="o">=</span> <span class="n">partition_file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">partition</span> <span class="o">=</span> <span class="n">partition</span>

        <span class="c1"># Load partition info</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">partitions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">partition_file</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">,</span> <span class="s1">&#39;partition&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">({</span><span class="s1">&#39;partition&#39;</span><span class="p">:</span> <span class="s1">&#39;int16&#39;</span><span class="p">})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">partitions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">partitions</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">partitions</span><span class="p">[</span><span class="s1">&#39;partition&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">partition</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">partitions</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">img_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">partitions</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">img_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_dir</span><span class="p">,</span> <span class="n">img_name</span><span class="p">)</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="mi">0</span> 


<span class="n">celeba_img_folder</span> <span class="o">=</span> <span class="s1">&#39;/home/sie/Documents/gen_ai_assignment/archive/img_align_celeba&#39;</span>
<span class="n">partition_file</span> <span class="o">=</span> <span class="s1">&#39;/home/sie/Documents/gen_ai_assignment/archive/list_eval_partition.csv&#39;</span>

<span class="c1"># Ensure the dataset folder exists</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">celeba_img_folder</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The directory &#39;</span><span class="si">{</span><span class="n">celeba_img_folder</span><span class="si">}</span><span class="s2">&#39; does not exist. Ensure dataset is downloaded correctly.&quot;</span><span class="p">)</span>

<span class="c1"># Create dataset objects for train, validation, and test</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">CelebADataset</span><span class="p">(</span><span class="n">img_dir</span><span class="o">=</span><span class="n">celeba_img_folder</span><span class="p">,</span> <span class="n">partition_file</span><span class="o">=</span><span class="n">partition_file</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">partition</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">CelebADataset</span><span class="p">(</span><span class="n">img_dir</span><span class="o">=</span><span class="n">celeba_img_folder</span><span class="p">,</span> <span class="n">partition_file</span><span class="o">=</span><span class="n">partition_file</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">partition</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">CelebADataset</span><span class="p">(</span><span class="n">img_dir</span><span class="o">=</span><span class="n">celeba_img_folder</span><span class="p">,</span> <span class="n">partition_file</span><span class="o">=</span><span class="n">partition_file</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">partition</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># DataLoaders</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Training loop</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">recon_batch</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">recon_batch</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># if batch_idx % 1500 == 0:</span>
        <span class="c1">#     break</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">, Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;vae_celeba.pth&#39;</span><span class="p">)</span>

<span class="c1"># Generate samples</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">generated</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

<span class="c1"># Save generated images</span>
<span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">save_image</span><span class="p">(</span><span class="n">generated</span><span class="p">,</span> <span class="s1">&#39;vae_samples.png&#39;</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training complete. Generated samples saved as &#39;vae_samples.png&#39;.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1, Loss: 0.0530
Epoch 2, Loss: 0.0525
Epoch 3, Loss: 0.0516
Epoch 4, Loss: 0.0502
Epoch 5, Loss: 0.0480
Epoch 6, Loss: 0.0450
Epoch 7, Loss: 0.0404
Epoch 8, Loss: 0.0339
Epoch 9, Loss: 0.0258
Epoch 10, Loss: 0.0140
Epoch 11, Loss: 0.0056
Epoch 12, Loss: -0.0165
Epoch 13, Loss: -0.0409
Epoch 14, Loss: -0.0974
Epoch 15, Loss: -0.2161
Epoch 16, Loss: -0.3767
Epoch 17, Loss: -0.6991
Epoch 18, Loss: -0.8694
Epoch 19, Loss: -1.0377
Epoch 20, Loss: -0.8122
Epoch 21, Loss: -0.9605
Epoch 22, Loss: -1.0560
Epoch 23, Loss: -0.8547
Epoch 24, Loss: -0.9755
Epoch 25, Loss: -0.8820
Epoch 26, Loss: -0.7723
Epoch 27, Loss: -0.6627
Epoch 28, Loss: -0.7291
Epoch 29, Loss: -1.0852
Epoch 30, Loss: -1.0087
Epoch 31, Loss: -1.0250
Epoch 32, Loss: -0.9891
Epoch 33, Loss: -1.1659
Epoch 34, Loss: -1.1493
Epoch 35, Loss: -1.2198
Epoch 36, Loss: -1.3464
Epoch 37, Loss: -1.1842
Epoch 38, Loss: -1.3797
Epoch 39, Loss: -1.3136
Epoch 40, Loss: -1.5400
Epoch 41, Loss: -1.3268
Epoch 42, Loss: -1.5113
Epoch 43, Loss: -1.2717
Epoch 44, Loss: -1.3394
Epoch 45, Loss: -1.3234
Epoch 46, Loss: -1.2503
Epoch 47, Loss: -1.2970
Epoch 48, Loss: -1.3914
Epoch 49, Loss: -1.3600
Epoch 50, Loss: -1.4677
Epoch 51, Loss: -1.3987
Epoch 52, Loss: -1.5128
Epoch 53, Loss: -1.4410
Epoch 54, Loss: -1.4249
Epoch 55, Loss: -1.3590
Epoch 56, Loss: -1.3896
Epoch 57, Loss: -1.5038
Epoch 58, Loss: -1.5492
Epoch 59, Loss: -1.6653
Epoch 60, Loss: -1.5654
Epoch 61, Loss: -1.5024
Epoch 62, Loss: -1.3573
Epoch 63, Loss: -1.7312
Epoch 64, Loss: -1.4572
Epoch 65, Loss: -1.6363
Epoch 66, Loss: -1.4562
Epoch 67, Loss: -1.5517
Epoch 68, Loss: -1.6782
Epoch 69, Loss: -1.6765
Epoch 70, Loss: -1.5724
Epoch 71, Loss: -1.5630
Epoch 72, Loss: -1.5530
Epoch 73, Loss: -1.7069
Epoch 74, Loss: -1.4970
Epoch 75, Loss: -1.5237
Epoch 76, Loss: -1.4621
Epoch 77, Loss: -1.4521
Epoch 78, Loss: -1.6461
Epoch 79, Loss: -1.5497
Epoch 80, Loss: -1.5623
Epoch 81, Loss: -1.5302
Epoch 82, Loss: -1.5525
Epoch 83, Loss: -1.3677
Epoch 84, Loss: -1.7073
Epoch 85, Loss: -1.5772
Epoch 86, Loss: -1.4703
Epoch 87, Loss: -1.6347
Epoch 88, Loss: -1.5893
Epoch 89, Loss: -1.7739
Epoch 90, Loss: -1.3954
Epoch 91, Loss: -1.5304
Epoch 92, Loss: -1.4850
Epoch 93, Loss: -1.5937
Epoch 94, Loss: -1.4539
Epoch 95, Loss: -1.5002
Epoch 96, Loss: -1.4992
Epoch 97, Loss: -1.5704
Epoch 98, Loss: -1.6972
Epoch 99, Loss: -1.7783
Epoch 100, Loss: -1.6149
Epoch 101, Loss: -1.3808
Epoch 102, Loss: -1.6925
Epoch 103, Loss: -1.5247
Epoch 104, Loss: -1.7976
Epoch 105, Loss: -1.4320
Epoch 106, Loss: -1.7034
Epoch 107, Loss: -1.5020
Epoch 108, Loss: -1.5126
Epoch 109, Loss: -1.8333
Epoch 110, Loss: -1.5280
Epoch 111, Loss: -1.7672
Epoch 112, Loss: -1.4887
Epoch 113, Loss: -1.5324
Epoch 114, Loss: -1.6136
Epoch 115, Loss: -1.5905
Epoch 116, Loss: -1.7305
Epoch 117, Loss: -1.8244
Epoch 118, Loss: -1.5916
Epoch 119, Loss: -1.7526
Epoch 120, Loss: -1.9671
Epoch 121, Loss: -1.6672
Epoch 122, Loss: -1.6449
Epoch 123, Loss: -1.7679
Epoch 124, Loss: -1.6519
Epoch 125, Loss: -1.7173
Epoch 126, Loss: -1.6383
Epoch 127, Loss: -1.8777
Epoch 128, Loss: -1.7076
Epoch 129, Loss: -1.8349
Epoch 130, Loss: -1.7631
Epoch 131, Loss: -1.7904
Epoch 132, Loss: -1.7696
Epoch 133, Loss: -1.7439
Epoch 134, Loss: -1.6958
Epoch 135, Loss: -1.7066
Epoch 136, Loss: -1.8065
Epoch 137, Loss: -1.7972
Epoch 138, Loss: -1.7774
Epoch 139, Loss: -1.7118
Epoch 140, Loss: -1.6641
Epoch 141, Loss: -1.8710
Epoch 142, Loss: -1.9330
Epoch 143, Loss: -1.6958
Epoch 144, Loss: -1.7453
Epoch 145, Loss: -1.6567
Epoch 146, Loss: -1.6244
Epoch 147, Loss: -1.7366
Epoch 148, Loss: -1.7413
Epoch 149, Loss: -1.8077
Epoch 150, Loss: -1.7423
Epoch 151, Loss: -1.7246
Epoch 152, Loss: -1.6784
Epoch 153, Loss: -1.6994
Epoch 154, Loss: -1.7857
Epoch 155, Loss: -1.7705
Epoch 156, Loss: -1.4797
Epoch 157, Loss: -1.7580
Epoch 158, Loss: -1.6438
Epoch 159, Loss: -1.5097
Epoch 160, Loss: -1.6356
Epoch 161, Loss: -1.6814
Epoch 162, Loss: -1.5325
Epoch 163, Loss: -1.9535
Epoch 164, Loss: -1.4917
Epoch 165, Loss: -1.6686
Epoch 166, Loss: -1.7295
Epoch 167, Loss: -1.6895
Epoch 168, Loss: -1.7497
Epoch 169, Loss: -1.9500
Epoch 170, Loss: -1.9161
Epoch 171, Loss: -1.6917
Epoch 172, Loss: -1.7608
Epoch 173, Loss: -1.7517
Epoch 174, Loss: -1.7437
Epoch 175, Loss: -1.6793
Epoch 176, Loss: -1.7008
Epoch 177, Loss: -1.7766
Epoch 178, Loss: -1.9460
Epoch 179, Loss: -1.6090
Epoch 180, Loss: -1.8149
Epoch 181, Loss: -1.7715
Epoch 182, Loss: -1.9715
Epoch 183, Loss: -1.6133
Epoch 184, Loss: -1.9230
Epoch 185, Loss: -2.1502
Epoch 186, Loss: -1.8862
Epoch 187, Loss: -1.7227
Epoch 188, Loss: -1.9530
Epoch 189, Loss: -1.8022
Epoch 190, Loss: -1.7026
Epoch 191, Loss: -1.9465
Epoch 192, Loss: -1.6965
Epoch 193, Loss: -1.9105
Epoch 194, Loss: -1.8201
Epoch 195, Loss: -1.9761
Epoch 196, Loss: -1.9647
Epoch 197, Loss: -1.8370
Epoch 198, Loss: -1.7141
Epoch 199, Loss: -1.8115
Epoch 200, Loss: -1.8191
Epoch 201, Loss: -1.7794
Epoch 202, Loss: -1.8745
Epoch 203, Loss: -1.9484
Epoch 204, Loss: -1.8774
Epoch 205, Loss: -1.7410
Epoch 206, Loss: -1.8434
Epoch 207, Loss: -1.9392
Epoch 208, Loss: -1.7867
Epoch 209, Loss: -1.8415
Epoch 210, Loss: -1.8783
Epoch 211, Loss: -2.0094
Epoch 212, Loss: -1.7870
Epoch 213, Loss: -1.8964
Epoch 214, Loss: -1.6896
Epoch 215, Loss: -1.8024
Epoch 216, Loss: -1.7599
Epoch 217, Loss: -1.8153
Epoch 218, Loss: -1.9153
Epoch 219, Loss: -1.7224
Epoch 220, Loss: -2.0057
Epoch 221, Loss: -1.7935
Epoch 222, Loss: -1.8657
Epoch 223, Loss: -1.7618
Epoch 224, Loss: -2.0132
Epoch 225, Loss: -1.8831
Epoch 226, Loss: -1.8181
Epoch 227, Loss: -1.7525
Epoch 228, Loss: -2.0025
Epoch 229, Loss: -1.9556
Epoch 230, Loss: -1.9329
Epoch 231, Loss: -1.8301
Epoch 232, Loss: -1.8299
Epoch 233, Loss: -1.9878
Epoch 234, Loss: -1.9645
Epoch 235, Loss: -1.8646
Epoch 236, Loss: -1.8976
Epoch 237, Loss: -1.7813
Epoch 238, Loss: -1.8592
Epoch 239, Loss: -1.8512
Epoch 240, Loss: -1.9350
Epoch 241, Loss: -2.1211
Epoch 242, Loss: -1.8515
Epoch 243, Loss: -1.8588
Epoch 244, Loss: -1.9051
Epoch 245, Loss: -1.7661
Epoch 246, Loss: -1.8706
Epoch 247, Loss: -1.8206
Epoch 248, Loss: -1.8584
Epoch 249, Loss: -1.9049
Epoch 250, Loss: -1.7717
Epoch 251, Loss: -1.9100
Epoch 252, Loss: -1.8079
Epoch 253, Loss: -1.8555
Epoch 254, Loss: -1.7767
Epoch 255, Loss: -2.1055
Epoch 256, Loss: -1.9673
Epoch 257, Loss: -1.9667
Epoch 258, Loss: -1.6727
Epoch 259, Loss: -1.8849
Epoch 260, Loss: -2.0563
Epoch 261, Loss: -1.7758
Epoch 262, Loss: -1.7853
Epoch 263, Loss: -1.9748
Epoch 264, Loss: -1.9287
Epoch 265, Loss: -1.7240
Epoch 266, Loss: -1.9691
Epoch 267, Loss: -1.8725
Epoch 268, Loss: -1.6090
Epoch 269, Loss: -2.0081
Epoch 270, Loss: -1.8363
Epoch 271, Loss: -1.8328
Epoch 272, Loss: -1.8718
Epoch 273, Loss: -1.9547
Epoch 274, Loss: -1.8218
Epoch 275, Loss: -1.9166
Epoch 276, Loss: -2.0386
Epoch 277, Loss: -1.8256
Epoch 278, Loss: -1.6121
Epoch 279, Loss: -1.7586
Epoch 280, Loss: -2.0904
Epoch 281, Loss: -1.8997
Epoch 282, Loss: -1.7709
Epoch 283, Loss: -1.8367
Epoch 284, Loss: -1.7336
Epoch 285, Loss: -1.8625
Epoch 286, Loss: -2.0124
Epoch 287, Loss: -1.9790
Epoch 288, Loss: -2.0474
Epoch 289, Loss: -1.9655
Epoch 290, Loss: -1.8892
Epoch 291, Loss: -2.0387
Epoch 292, Loss: -1.8051
Epoch 293, Loss: -2.2249
Epoch 294, Loss: -1.8719
Epoch 295, Loss: -1.9486
Epoch 296, Loss: -1.9045
Epoch 297, Loss: -1.8707
Epoch 298, Loss: -1.9785
Epoch 299, Loss: -1.7359
Epoch 300, Loss: -1.9908
Epoch 301, Loss: -2.0416
Epoch 302, Loss: -1.9841
Epoch 303, Loss: -1.9853
Epoch 304, Loss: -1.9411
Epoch 305, Loss: -2.0922
Epoch 306, Loss: -2.0133
Epoch 307, Loss: -1.9890
Epoch 308, Loss: -1.9257
Epoch 309, Loss: -1.9227
Epoch 310, Loss: -1.9686
Epoch 311, Loss: -2.0891
Epoch 312, Loss: -1.8880
Epoch 313, Loss: -1.5900
Epoch 314, Loss: -2.0250
Epoch 315, Loss: -1.9543
Epoch 316, Loss: -1.8726
Epoch 317, Loss: -1.8646
Epoch 318, Loss: -1.7932
Epoch 319, Loss: -1.8597
Epoch 320, Loss: -1.9151
Epoch 321, Loss: -1.9703
Epoch 322, Loss: -1.8969
Epoch 323, Loss: -1.8986
Epoch 324, Loss: -1.9404
Epoch 325, Loss: -2.1028
Epoch 326, Loss: -2.0577
Epoch 327, Loss: -1.8450
Epoch 328, Loss: -1.8535
Epoch 329, Loss: -2.0768
Epoch 330, Loss: -1.7030
Epoch 331, Loss: -2.0686
Epoch 332, Loss: -1.8706
Epoch 333, Loss: -1.9657
Epoch 334, Loss: -1.9583
Epoch 335, Loss: -1.9139
Epoch 336, Loss: -2.1602
Epoch 337, Loss: -1.6695
Epoch 338, Loss: -1.8459
Epoch 339, Loss: -1.7757
Epoch 340, Loss: -2.2117
Epoch 341, Loss: -2.1223
Epoch 342, Loss: -2.0330
Epoch 343, Loss: -2.0265
Epoch 344, Loss: -1.7898
Epoch 345, Loss: -2.0248
Epoch 346, Loss: -2.0696
Epoch 347, Loss: -1.9227
Epoch 348, Loss: -2.0340
Epoch 349, Loss: -2.0754
Epoch 350, Loss: -1.8511
Epoch 351, Loss: -1.9494
Epoch 352, Loss: -2.0350
Epoch 353, Loss: -2.0602
Epoch 354, Loss: -1.9714
Epoch 355, Loss: -1.8626
Epoch 356, Loss: -1.9504
Epoch 357, Loss: -1.8546
Epoch 358, Loss: -1.8517
Epoch 359, Loss: -1.8609
Epoch 360, Loss: -1.8440
Epoch 361, Loss: -2.1363
Epoch 362, Loss: -2.1826
Epoch 363, Loss: -1.9440
Epoch 364, Loss: -2.0192
Epoch 365, Loss: -1.7602
Epoch 366, Loss: -2.1366
Epoch 367, Loss: -2.0823
Epoch 368, Loss: -2.1321
Epoch 369, Loss: -2.0731
Epoch 370, Loss: -1.8772
Epoch 371, Loss: -1.9638
Epoch 372, Loss: -2.0340
Epoch 373, Loss: -1.9790
Epoch 374, Loss: -1.9514
Epoch 375, Loss: -1.7921
Epoch 376, Loss: -1.8072
Epoch 377, Loss: -2.1556
Epoch 378, Loss: -1.9276
Epoch 379, Loss: -1.8706
Epoch 380, Loss: -2.1195
Epoch 381, Loss: -1.9802
Epoch 382, Loss: -1.9884
Epoch 383, Loss: -2.0732
Epoch 384, Loss: -1.9335
Epoch 385, Loss: -1.9662
Epoch 386, Loss: -1.9408
Epoch 387, Loss: -1.9200
Epoch 388, Loss: -2.0723
Epoch 389, Loss: -2.1719
Epoch 390, Loss: -2.0528
Epoch 391, Loss: -2.0221
Epoch 392, Loss: -2.0650
Epoch 393, Loss: -2.0107
Epoch 394, Loss: -2.0303
Epoch 395, Loss: -2.0463
Epoch 396, Loss: -2.0091
Epoch 397, Loss: -1.9434
Epoch 398, Loss: -2.0557
Epoch 399, Loss: -2.0320
Epoch 400, Loss: -1.8075
Epoch 401, Loss: -1.8263
Epoch 402, Loss: -1.9081
Epoch 403, Loss: -1.9254
Epoch 404, Loss: -1.9689
Epoch 405, Loss: -1.9804
Epoch 406, Loss: -2.1084
Epoch 407, Loss: -1.9713
Epoch 408, Loss: -1.8450
Epoch 409, Loss: -2.0049
Epoch 410, Loss: -2.1186
Epoch 411, Loss: -2.0078
Epoch 412, Loss: -2.1114
Epoch 413, Loss: -2.0295
Epoch 414, Loss: -1.8421
Epoch 415, Loss: -1.7807
Epoch 416, Loss: -2.0965
Epoch 417, Loss: -1.9007
Epoch 418, Loss: -2.0144
Epoch 419, Loss: -2.2482
Epoch 420, Loss: -1.9207
Epoch 421, Loss: -1.9958
Epoch 422, Loss: -2.1922
Epoch 423, Loss: -1.9873
Epoch 424, Loss: -1.8118
Epoch 425, Loss: -2.0152
Epoch 426, Loss: -2.0176
Epoch 427, Loss: -2.0177
Epoch 428, Loss: -2.0415
Epoch 429, Loss: -2.1661
Epoch 430, Loss: -2.0926
Epoch 431, Loss: -2.0767
Epoch 432, Loss: -1.8223
Epoch 433, Loss: -2.1628
Epoch 434, Loss: -2.1743
Epoch 435, Loss: -1.9635
Epoch 436, Loss: -2.1341
Epoch 437, Loss: -1.8411
Epoch 438, Loss: -1.9007
Epoch 439, Loss: -1.9529
Epoch 440, Loss: -2.0441
Epoch 441, Loss: -2.0858
Epoch 442, Loss: -2.1483
Epoch 443, Loss: -2.0363
Epoch 444, Loss: -1.9210
Epoch 445, Loss: -1.8536
Epoch 446, Loss: -1.9789
Epoch 447, Loss: -1.9924
Epoch 448, Loss: -1.7669
Epoch 449, Loss: -2.0766
Epoch 450, Loss: -1.9937
Epoch 451, Loss: -2.0299
Epoch 452, Loss: -2.0149
Epoch 453, Loss: -2.2642
Epoch 454, Loss: -2.0486
Epoch 455, Loss: -2.1315
Epoch 456, Loss: -2.0000
Epoch 457, Loss: -1.8057
Epoch 458, Loss: -1.9878
Epoch 459, Loss: -2.0132
Epoch 460, Loss: -2.0478
Epoch 461, Loss: -2.1779
Epoch 462, Loss: -1.9898
Epoch 463, Loss: -1.9388
Epoch 464, Loss: -1.8976
Epoch 465, Loss: -1.9940
Epoch 466, Loss: -2.0213
Epoch 467, Loss: -1.9958
Epoch 468, Loss: -2.1731
Epoch 469, Loss: -1.9377
Epoch 470, Loss: -2.0004
Epoch 471, Loss: -2.0224
Epoch 472, Loss: -2.2780
Epoch 473, Loss: -2.1567
Epoch 474, Loss: -1.9990
Epoch 475, Loss: -1.8006
Epoch 476, Loss: -2.0457
Epoch 477, Loss: -1.9881
Epoch 478, Loss: -2.0164
Epoch 479, Loss: -2.2633
Epoch 480, Loss: -2.0375
Epoch 481, Loss: -1.9805
Epoch 482, Loss: -2.0187
Epoch 483, Loss: -2.2518
Epoch 484, Loss: -2.1039
Epoch 485, Loss: -2.2193
Epoch 486, Loss: -2.2537
Epoch 487, Loss: -2.1964
Epoch 488, Loss: -1.9560
Epoch 489, Loss: -1.8354
Epoch 490, Loss: -2.1301
Epoch 491, Loss: -2.0489
Epoch 492, Loss: -1.9568
Epoch 493, Loss: -2.0581
Epoch 494, Loss: -2.0136
Epoch 495, Loss: -1.9468
Epoch 496, Loss: -1.9266
Epoch 497, Loss: -2.0088
Epoch 498, Loss: -1.9410
Epoch 499, Loss: -2.0881
Epoch 500, Loss: -2.1756
Training complete. Generated samples saved as &#39;vae_samples.png&#39;.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generated samples are</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;vae_samples.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/67023ba2871d06f7669e0e1f02d79bf57f1b68535a031baf7ba932573683a075.png" src="../_images/67023ba2871d06f7669e0e1f02d79bf57f1b68535a031baf7ba932573683a075.png" />
</div>
</div>
</section>
<section id="latent-space-arithmetic-make-your-image-smile-generate-smiling-face-images-by-playing-with-latent-space-z-vector">
<h3>2. Latent Space arithmetic - Make your image smile. Generate smiling face images by playing with latent space z vector.<a class="headerlink" href="#latent-space-arithmetic-make-your-image-smile-generate-smiling-face-images-by-playing-with-latent-space-z-vector" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="c1"># Load the attribute labels</span>
<span class="n">attribute_file</span> <span class="o">=</span> <span class="s1">&#39;./archive/list_attr_celeba.csv&#39;</span>
<span class="n">attributes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">attribute_file</span><span class="p">)</span>

<span class="c1"># Select the &quot;Smiling&quot; attribute</span>
<span class="n">smiling_imgs</span> <span class="o">=</span> <span class="n">attributes</span><span class="p">[</span><span class="n">attributes</span><span class="p">[</span><span class="s1">&#39;Smiling&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s1">&#39;image_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">not_smiling_imgs</span> <span class="o">=</span> <span class="n">attributes</span><span class="p">[</span><span class="n">attributes</span><span class="p">[</span><span class="s1">&#39;Smiling&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;image_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="k">def</span> <span class="nf">compute_average_embedding</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">img_dir</span><span class="p">,</span> <span class="n">img_list</span><span class="p">,</span> <span class="n">transform</span><span class="p">):</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">img_name</span> <span class="ow">in</span> <span class="n">img_list</span><span class="p">:</span>
            <span class="n">img_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">img_dir</span><span class="p">,</span> <span class="n">img_name</span><span class="p">)</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
            <span class="n">embeddings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
    <span class="n">avg_embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">avg_embedding</span>

<span class="c1"># Compute smile and no-smile embeddings</span>
<span class="n">smiling_avg_embedding</span> <span class="o">=</span> <span class="n">compute_average_embedding</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">celeba_img_folder</span><span class="p">,</span> <span class="n">smiling_imgs</span><span class="p">,</span> <span class="n">transform</span><span class="p">)</span>
<span class="n">not_smiling_avg_embedding</span> <span class="o">=</span> <span class="n">compute_average_embedding</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">celeba_img_folder</span><span class="p">,</span> <span class="n">not_smiling_imgs</span><span class="p">,</span> <span class="n">transform</span><span class="p">)</span>

<span class="n">smile_vector</span> <span class="o">=</span> <span class="n">smiling_avg_embedding</span> <span class="o">-</span> <span class="n">not_smiling_avg_embedding</span>

<span class="k">def</span> <span class="nf">add_smile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">smile_vector</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="c1"># Encode the image</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>

        <span class="c1"># Modify the latent space by adding the smile vector</span>
        <span class="n">z_smile</span> <span class="o">=</span> <span class="n">z</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">smile_vector</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Decode the modified latent vector</span>
        <span class="n">img_smile</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z_smile</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">img_smile</span>

<span class="c1"># Load and manipulate a test image</span>
<span class="n">img_path</span> <span class="o">=</span> <span class="s1">&#39;non_smiling.jpg&#39;</span>
<span class="n">test_img</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">img_with_smile</span> <span class="o">=</span> <span class="n">add_smile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_img</span><span class="p">,</span> <span class="n">smile_vector</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># Save the generated smiling image</span>
<span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">save_image</span><span class="p">(</span><span class="n">img_with_smile</span><span class="p">,</span> <span class="s1">&#39;smiling_image.png&#39;</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Generate a more intense smile</span>
<span class="n">img_with_big_smile</span> <span class="o">=</span> <span class="n">add_smile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_img</span><span class="p">,</span> <span class="n">smile_vector</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
<span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">save_image</span><span class="p">(</span><span class="n">img_with_big_smile</span><span class="p">,</span> <span class="s1">&#39;big_smile_image.png&#39;</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generated smiling image</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;smiling_image.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/f2dea833580f13152d0f5be9f13d50f241b407a8ddfa4a18c5b42c40f660a392.png" src="../_images/f2dea833580f13152d0f5be9f13d50f241b407a8ddfa4a18c5b42c40f660a392.png" />
</div>
</div>
</section>
</section>
<section id="variants-of-gans">
<h2>2.2 Variants of GANs<a class="headerlink" href="#variants-of-gans" title="Link to this heading">#</a></h2>
<section id="implement-a-standard-gan-on-mnist-cifar-10-data-plot-generator-loss-discriminator-loss-and-classification-accuracy-of-discriminator-with-respect-to-iterations">
<h3>1. Implement a standard GAN on MNIST/CIFAR-10 data. Plot Generator loss, Discriminator Loss and Classification accuracy of discriminator with respect to iterations.<a class="headerlink" href="#implement-a-standard-gan-on-mnist-cifar-10-data-plot-generator-loss-discriminator-loss-and-classification-accuracy-of-discriminator-with-respect-to-iterations" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Set random seed</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Hyperparameters</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">image_dim</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0002</span>

<span class="c1"># Device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="c1"># MNIST Dataset</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">])</span>
<span class="p">])</span>

<span class="n">mnist_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">mnist_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Generator</span>
<span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>

<span class="c1"># Discriminator</span>
<span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="n">img_flat</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">validity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">img_flat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">validity</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">discriminator</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">optimizer_G</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">optimizer_D</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="c1"># Loss function</span>
<span class="n">adversarial_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>

<span class="c1"># Training loop</span>
<span class="n">G_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">D_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">D_accuracies</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">real_imgs</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">real_imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">real_imgs</span> <span class="o">=</span> <span class="n">real_imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">fake</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Train Generator</span>
        <span class="n">optimizer_G</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">gen_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">g_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">),</span> <span class="n">valid</span><span class="p">)</span>
        <span class="n">g_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer_G</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Train Discriminator</span>
        <span class="n">optimizer_D</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">real_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">),</span> <span class="n">valid</span><span class="p">)</span>
        <span class="n">fake_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="o">.</span><span class="n">detach</span><span class="p">()),</span> <span class="n">fake</span><span class="p">)</span>
        <span class="n">d_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">real_loss</span> <span class="o">+</span> <span class="n">fake_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="n">d_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer_D</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Calculate discriminator accuracy</span>
        <span class="n">d_real_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">d_fake_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">d_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">d_real_accuracy</span> <span class="o">+</span> <span class="n">d_fake_accuracy</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="n">G_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">g_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">D_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">D_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d_accuracy</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">] [Batch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2">] &quot;</span>
           <span class="sa">f</span><span class="s2">&quot;[D loss: </span><span class="si">{</span><span class="n">d_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">] [G loss: </span><span class="si">{</span><span class="n">g_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">] &quot;</span>
           <span class="sa">f</span><span class="s2">&quot;[D accuracy: </span><span class="si">{</span><span class="n">d_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;generator.pth&#39;</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">discriminator</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;discriminator.pth&#39;</span><span class="p">)</span>

<span class="c1"># Plot losses and accuracy</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">G_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Generator Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">D_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Discriminator Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">D_accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Discriminator Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Iterations&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss / Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;GAN Training Progress&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;gan_training_progress.png&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training complete. Progress plot saved as &#39;gan_training_progress.png&#39;.&quot;</span><span class="p">)</span>

<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">gen_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

<span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;gan_generated_samples.png&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample images generated and saved as &#39;gan_generated_samples.png&#39;.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Epoch 0/100] [Batch 937/938] [D loss: 0.0159] [G loss: 3.8533] [D accuracy: 1.0000]
[Epoch 1/100] [Batch 937/938] [D loss: 0.1070] [G loss: 2.4122] [D accuracy: 0.9688]
[Epoch 2/100] [Batch 937/938] [D loss: 0.3842] [G loss: 1.5592] [D accuracy: 0.9219]
[Epoch 3/100] [Batch 937/938] [D loss: 0.1589] [G loss: 2.1942] [D accuracy: 0.9531]
[Epoch 4/100] [Batch 937/938] [D loss: 0.0753] [G loss: 4.5895] [D accuracy: 0.9844]
[Epoch 5/100] [Batch 937/938] [D loss: 0.1489] [G loss: 4.3297] [D accuracy: 0.9688]
[Epoch 6/100] [Batch 937/938] [D loss: 0.2573] [G loss: 2.9687] [D accuracy: 0.9375]
[Epoch 7/100] [Batch 937/938] [D loss: 0.0965] [G loss: 6.1343] [D accuracy: 0.9688]
[Epoch 8/100] [Batch 937/938] [D loss: 0.0945] [G loss: 2.8061] [D accuracy: 0.9844]
[Epoch 9/100] [Batch 937/938] [D loss: 0.2093] [G loss: 5.0216] [D accuracy: 0.9531]
[Epoch 10/100] [Batch 937/938] [D loss: 0.0917] [G loss: 4.2588] [D accuracy: 0.9688]
[Epoch 11/100] [Batch 937/938] [D loss: 0.1860] [G loss: 4.6545] [D accuracy: 0.9688]
[Epoch 12/100] [Batch 937/938] [D loss: 0.1135] [G loss: 4.3967] [D accuracy: 0.9688]
[Epoch 13/100] [Batch 937/938] [D loss: 0.1308] [G loss: 5.6214] [D accuracy: 0.9531]
[Epoch 14/100] [Batch 937/938] [D loss: 0.1483] [G loss: 3.7953] [D accuracy: 0.9531]
[Epoch 15/100] [Batch 937/938] [D loss: 0.1455] [G loss: 3.9646] [D accuracy: 0.9844]
[Epoch 16/100] [Batch 937/938] [D loss: 0.1146] [G loss: 4.5039] [D accuracy: 0.9688]
[Epoch 17/100] [Batch 937/938] [D loss: 0.1003] [G loss: 3.9653] [D accuracy: 0.9531]
[Epoch 18/100] [Batch 937/938] [D loss: 0.1990] [G loss: 3.4776] [D accuracy: 0.9531]
[Epoch 19/100] [Batch 937/938] [D loss: 0.0770] [G loss: 3.5766] [D accuracy: 0.9688]
[Epoch 20/100] [Batch 937/938] [D loss: 0.1225] [G loss: 4.8707] [D accuracy: 0.9688]
[Epoch 21/100] [Batch 937/938] [D loss: 0.2121] [G loss: 4.8175] [D accuracy: 0.9688]
[Epoch 22/100] [Batch 937/938] [D loss: 0.0946] [G loss: 3.4265] [D accuracy: 0.9688]
[Epoch 23/100] [Batch 937/938] [D loss: 0.2337] [G loss: 3.2521] [D accuracy: 0.9062]
[Epoch 24/100] [Batch 937/938] [D loss: 0.3267] [G loss: 3.4617] [D accuracy: 0.8594]
[Epoch 25/100] [Batch 937/938] [D loss: 0.2238] [G loss: 4.2238] [D accuracy: 0.9375]
[Epoch 26/100] [Batch 937/938] [D loss: 0.2196] [G loss: 4.4033] [D accuracy: 0.9375]
[Epoch 27/100] [Batch 937/938] [D loss: 0.2179] [G loss: 2.6610] [D accuracy: 0.9531]
[Epoch 28/100] [Batch 937/938] [D loss: 0.2740] [G loss: 2.0128] [D accuracy: 0.9375]
[Epoch 29/100] [Batch 937/938] [D loss: 0.4264] [G loss: 2.5450] [D accuracy: 0.8750]
[Epoch 30/100] [Batch 937/938] [D loss: 0.2786] [G loss: 2.3725] [D accuracy: 0.9062]
[Epoch 31/100] [Batch 937/938] [D loss: 0.2550] [G loss: 2.4565] [D accuracy: 0.8750]
[Epoch 32/100] [Batch 937/938] [D loss: 0.2482] [G loss: 2.0177] [D accuracy: 0.9219]
[Epoch 33/100] [Batch 937/938] [D loss: 0.2447] [G loss: 4.0631] [D accuracy: 0.9531]
[Epoch 34/100] [Batch 937/938] [D loss: 0.3751] [G loss: 2.4915] [D accuracy: 0.9062]
[Epoch 35/100] [Batch 937/938] [D loss: 0.2888] [G loss: 4.1763] [D accuracy: 0.8750]
[Epoch 36/100] [Batch 937/938] [D loss: 0.3018] [G loss: 2.4237] [D accuracy: 0.8750]
[Epoch 37/100] [Batch 937/938] [D loss: 0.3832] [G loss: 2.7287] [D accuracy: 0.8438]
[Epoch 38/100] [Batch 937/938] [D loss: 0.3192] [G loss: 2.7066] [D accuracy: 0.9062]
[Epoch 39/100] [Batch 937/938] [D loss: 0.3316] [G loss: 2.2206] [D accuracy: 0.8594]
[Epoch 40/100] [Batch 937/938] [D loss: 0.5255] [G loss: 1.7958] [D accuracy: 0.7969]
[Epoch 41/100] [Batch 937/938] [D loss: 0.1055] [G loss: 4.0140] [D accuracy: 0.9531]
[Epoch 42/100] [Batch 937/938] [D loss: 0.2261] [G loss: 2.4748] [D accuracy: 0.9531]
[Epoch 43/100] [Batch 937/938] [D loss: 0.3286] [G loss: 3.9279] [D accuracy: 0.8906]
[Epoch 44/100] [Batch 937/938] [D loss: 0.1408] [G loss: 2.4440] [D accuracy: 0.9688]
[Epoch 45/100] [Batch 937/938] [D loss: 0.3038] [G loss: 1.8903] [D accuracy: 0.8906]
[Epoch 46/100] [Batch 937/938] [D loss: 0.3367] [G loss: 2.5202] [D accuracy: 0.8906]
[Epoch 47/100] [Batch 937/938] [D loss: 0.4080] [G loss: 1.8239] [D accuracy: 0.8281]
[Epoch 48/100] [Batch 937/938] [D loss: 0.4725] [G loss: 1.8652] [D accuracy: 0.8906]
[Epoch 49/100] [Batch 937/938] [D loss: 0.3785] [G loss: 1.4682] [D accuracy: 0.9062]
[Epoch 50/100] [Batch 937/938] [D loss: 0.4340] [G loss: 2.3096] [D accuracy: 0.8906]
[Epoch 51/100] [Batch 937/938] [D loss: 0.3229] [G loss: 2.7126] [D accuracy: 0.9062]
[Epoch 52/100] [Batch 937/938] [D loss: 0.4333] [G loss: 1.1146] [D accuracy: 0.9062]
[Epoch 53/100] [Batch 937/938] [D loss: 0.6873] [G loss: 3.6313] [D accuracy: 0.8281]
[Epoch 54/100] [Batch 937/938] [D loss: 0.1838] [G loss: 2.5913] [D accuracy: 0.9688]
[Epoch 55/100] [Batch 937/938] [D loss: 0.3229] [G loss: 2.1300] [D accuracy: 0.9062]
[Epoch 56/100] [Batch 937/938] [D loss: 0.4588] [G loss: 1.2840] [D accuracy: 0.8438]
[Epoch 57/100] [Batch 937/938] [D loss: 0.3759] [G loss: 1.8020] [D accuracy: 0.8125]
[Epoch 58/100] [Batch 937/938] [D loss: 0.3108] [G loss: 2.9394] [D accuracy: 0.8594]
[Epoch 59/100] [Batch 937/938] [D loss: 0.6075] [G loss: 1.4900] [D accuracy: 0.7500]
[Epoch 60/100] [Batch 937/938] [D loss: 0.4147] [G loss: 2.3824] [D accuracy: 0.8281]
[Epoch 61/100] [Batch 937/938] [D loss: 0.2775] [G loss: 1.9907] [D accuracy: 0.9062]
[Epoch 62/100] [Batch 937/938] [D loss: 0.3534] [G loss: 1.8204] [D accuracy: 0.8750]
[Epoch 63/100] [Batch 937/938] [D loss: 0.3184] [G loss: 3.3087] [D accuracy: 0.9375]
[Epoch 64/100] [Batch 937/938] [D loss: 0.2693] [G loss: 2.4433] [D accuracy: 0.9219]
[Epoch 65/100] [Batch 937/938] [D loss: 0.4062] [G loss: 1.9712] [D accuracy: 0.8281]
[Epoch 66/100] [Batch 937/938] [D loss: 0.4352] [G loss: 2.3600] [D accuracy: 0.8281]
[Epoch 67/100] [Batch 937/938] [D loss: 0.4311] [G loss: 2.5961] [D accuracy: 0.8438]
[Epoch 68/100] [Batch 937/938] [D loss: 0.4127] [G loss: 1.4460] [D accuracy: 0.8750]
[Epoch 69/100] [Batch 937/938] [D loss: 0.5037] [G loss: 0.9685] [D accuracy: 0.7969]
[Epoch 70/100] [Batch 937/938] [D loss: 0.3458] [G loss: 1.9713] [D accuracy: 0.8125]
[Epoch 71/100] [Batch 937/938] [D loss: 0.4300] [G loss: 2.0075] [D accuracy: 0.8125]
[Epoch 72/100] [Batch 937/938] [D loss: 0.4233] [G loss: 1.9131] [D accuracy: 0.8438]
[Epoch 73/100] [Batch 937/938] [D loss: 0.3969] [G loss: 1.7858] [D accuracy: 0.8438]
[Epoch 74/100] [Batch 937/938] [D loss: 0.3233] [G loss: 2.0642] [D accuracy: 0.9219]
[Epoch 75/100] [Batch 937/938] [D loss: 0.4514] [G loss: 1.8654] [D accuracy: 0.8438]
[Epoch 76/100] [Batch 937/938] [D loss: 0.5605] [G loss: 1.9414] [D accuracy: 0.7188]
[Epoch 77/100] [Batch 937/938] [D loss: 0.3783] [G loss: 1.7880] [D accuracy: 0.8281]
[Epoch 78/100] [Batch 937/938] [D loss: 0.3617] [G loss: 1.4791] [D accuracy: 0.8906]
[Epoch 79/100] [Batch 937/938] [D loss: 0.3729] [G loss: 2.3131] [D accuracy: 0.8750]
[Epoch 80/100] [Batch 937/938] [D loss: 0.4265] [G loss: 2.1273] [D accuracy: 0.7812]
[Epoch 81/100] [Batch 937/938] [D loss: 0.4878] [G loss: 2.0223] [D accuracy: 0.7656]
[Epoch 82/100] [Batch 937/938] [D loss: 0.6391] [G loss: 1.4069] [D accuracy: 0.7500]
[Epoch 83/100] [Batch 937/938] [D loss: 0.4548] [G loss: 2.2925] [D accuracy: 0.8125]
[Epoch 84/100] [Batch 937/938] [D loss: 0.4156] [G loss: 1.6484] [D accuracy: 0.8906]
[Epoch 85/100] [Batch 937/938] [D loss: 0.4033] [G loss: 1.3781] [D accuracy: 0.8125]
[Epoch 86/100] [Batch 937/938] [D loss: 0.2685] [G loss: 2.5171] [D accuracy: 0.9375]
[Epoch 87/100] [Batch 937/938] [D loss: 0.3418] [G loss: 1.9289] [D accuracy: 0.8906]
[Epoch 88/100] [Batch 937/938] [D loss: 0.3162] [G loss: 1.6208] [D accuracy: 0.9219]
[Epoch 89/100] [Batch 937/938] [D loss: 0.4039] [G loss: 2.1893] [D accuracy: 0.8438]
[Epoch 90/100] [Batch 937/938] [D loss: 0.5236] [G loss: 1.5786] [D accuracy: 0.7031]
[Epoch 91/100] [Batch 937/938] [D loss: 0.3967] [G loss: 1.6860] [D accuracy: 0.7969]
[Epoch 92/100] [Batch 937/938] [D loss: 0.5636] [G loss: 1.2642] [D accuracy: 0.7656]
[Epoch 93/100] [Batch 937/938] [D loss: 0.3767] [G loss: 2.0487] [D accuracy: 0.8750]
[Epoch 94/100] [Batch 937/938] [D loss: 0.4554] [G loss: 1.8869] [D accuracy: 0.7812]
[Epoch 95/100] [Batch 937/938] [D loss: 0.4145] [G loss: 1.7127] [D accuracy: 0.8125]
[Epoch 96/100] [Batch 937/938] [D loss: 0.4192] [G loss: 1.7226] [D accuracy: 0.8906]
[Epoch 97/100] [Batch 937/938] [D loss: 0.4566] [G loss: 1.5513] [D accuracy: 0.7656]
[Epoch 98/100] [Batch 937/938] [D loss: 0.4695] [G loss: 1.5480] [D accuracy: 0.7969]
[Epoch 99/100] [Batch 937/938] [D loss: 0.4460] [G loss: 1.5126] [D accuracy: 0.8438]
Training complete. Progress plot saved as &#39;gan_training_progress.png&#39;.
Sample images generated and saved as &#39;gan_generated_samples.png&#39;.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;gan_training_progress.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/cea3a73bfba4e08a6cb31cedfec8838a0f4f62fb354546167398e5cadbf350e0.png" src="../_images/cea3a73bfba4e08a6cb31cedfec8838a0f4f62fb354546167398e5cadbf350e0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Image</span><span class="p">(</span><span class="s1">&#39;gan_generated_samples.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d60b456de093423201d39e592570bb7f0653cbf7903951c5625b4ad426102d39.png" src="../_images/d60b456de093423201d39e592570bb7f0653cbf7903951c5625b4ad426102d39.png" />
</div>
</div>
</section>
<section id="demonstrate-the-vanishing-gradient-problem-of-standard-gan-by-training-your-gan-for-5-10-and-25-epochs-then-stop-the-gan-training-train-only-the-discriminator-till-it-reaches-100-accuracy-and-then-use-this-perfect-discriminator-to-train-your-gan-plot-the-generator-loss-gradient-norm-and-discriminator-loss-w-r-t-epochs-using-your-perfect-discriminator">
<h3>2. Demonstrate the vanishing gradient problem of standard GAN by training your GAN for 5,10 and 25 epochs. Then stop the GAN training, train only the discriminator till it reaches 100% accuracy and then use this perfect discriminator to train your GAN. Plot the generator loss/gradient norm and discriminator loss w.r.t epochs (using your perfect discriminator).<a class="headerlink" href="#demonstrate-the-vanishing-gradient-problem-of-standard-gan-by-training-your-gan-for-5-10-and-25-epochs-then-stop-the-gan-training-train-only-the-discriminator-till-it-reaches-100-accuracy-and-then-use-this-perfect-discriminator-to-train-your-gan-plot-the-generator-loss-gradient-norm-and-discriminator-loss-w-r-t-epochs-using-your-perfect-discriminator" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Hyperparameters</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">image_dim</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">25</span><span class="p">]</span> 
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0002</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">])</span>
<span class="p">])</span>

<span class="n">mnist_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">mnist_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Generator</span>
<span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>

<span class="c1"># Discriminator</span>
<span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="n">img_flat</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">validity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">img_flat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">validity</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">discriminator</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">optimizer_G</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">optimizer_D</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="c1"># Loss function</span>
<span class="n">adversarial_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>

<span class="n">G_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">D_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">D_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">grad_norms</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">def</span> <span class="nf">train_gan</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">real_imgs</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">real_imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">real_imgs</span> <span class="o">=</span> <span class="n">real_imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Ground truths</span>
            <span class="n">valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">fake</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Train Generator</span>
            <span class="n">optimizer_G</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">gen_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">g_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">),</span> <span class="n">valid</span><span class="p">)</span>
            <span class="n">g_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]))</span>
            <span class="n">grad_norms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

            <span class="n">optimizer_G</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># Train Discriminator</span>
            <span class="n">optimizer_D</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">real_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">),</span> <span class="n">valid</span><span class="p">)</span>
            <span class="n">fake_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="o">.</span><span class="n">detach</span><span class="p">()),</span> <span class="n">fake</span><span class="p">)</span>
            <span class="n">d_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">real_loss</span> <span class="o">+</span> <span class="n">fake_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">d_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer_D</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># Calculate discriminator accuracy</span>
            <span class="n">d_real_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">d_fake_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">d_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">d_real_accuracy</span> <span class="o">+</span> <span class="n">d_fake_accuracy</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

            <span class="n">G_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">g_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">D_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">D_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d_accuracy</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">] [Batch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2">] &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;[D loss: </span><span class="si">{</span><span class="n">d_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">] [G loss: </span><span class="si">{</span><span class="n">g_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">] &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;[D accuracy: </span><span class="si">{</span><span class="n">d_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

<span class="c1"># Train GAN for 5, 10, and 25 epochs separately </span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">num_epochs</span><span class="p">:</span>
    <span class="n">train_gan</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_discriminator_only</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>  
        <span class="k">for</span> <span class="n">real_imgs</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">real_imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">real_imgs</span> <span class="o">=</span> <span class="n">real_imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">fake</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">gen_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

            <span class="n">optimizer_D</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">real_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">),</span> <span class="n">valid</span><span class="p">)</span>
            <span class="n">fake_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">),</span> <span class="n">fake</span><span class="p">)</span>
            <span class="n">d_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">real_loss</span> <span class="o">+</span> <span class="n">fake_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">d_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer_D</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">d_real_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">d_fake_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">d_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">d_real_accuracy</span> <span class="o">+</span> <span class="n">d_fake_accuracy</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

            <span class="k">if</span> <span class="n">d_accuracy</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">:</span>  <span class="c1"># Stop when 100% accuracy is achieved</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Discriminator reached 100</span><span class="si">% a</span><span class="s2">ccuracy!&quot;</span><span class="p">)</span>
                <span class="k">return</span>

<span class="n">train_discriminator_only</span><span class="p">()</span>

<span class="n">train_gan</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>

<span class="c1"># Plot losses and accuracy</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">G_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Generator Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">D_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Discriminator Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">D_accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Discriminator Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Losses and Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grad_norms</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Gradient Norm of Generator&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Gradient Norm of Generator&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Epoch 0/5] [Batch 234/235] [D loss: 0.0144] [G loss: 3.9575] [D accuracy: 1.0000]
[Epoch 1/5] [Batch 234/235] [D loss: 0.0401] [G loss: 3.6167] [D accuracy: 0.9844]
[Epoch 2/5] [Batch 234/235] [D loss: 0.0328] [G loss: 4.1372] [D accuracy: 0.9948]
[Epoch 3/5] [Batch 234/235] [D loss: 0.0226] [G loss: 4.1470] [D accuracy: 0.9948]
[Epoch 4/5] [Batch 234/235] [D loss: 0.1277] [G loss: 3.7552] [D accuracy: 0.9844]
[Epoch 0/10] [Batch 234/235] [D loss: 0.0364] [G loss: 3.2813] [D accuracy: 1.0000]
[Epoch 1/10] [Batch 234/235] [D loss: 0.1341] [G loss: 3.2018] [D accuracy: 0.9792]
[Epoch 2/10] [Batch 234/235] [D loss: 0.1045] [G loss: 3.2027] [D accuracy: 0.9688]
[Epoch 3/10] [Batch 234/235] [D loss: 0.1653] [G loss: 2.5413] [D accuracy: 0.9688]
[Epoch 4/10] [Batch 234/235] [D loss: 0.2955] [G loss: 2.0764] [D accuracy: 0.9375]
[Epoch 5/10] [Batch 234/235] [D loss: 0.2134] [G loss: 3.1298] [D accuracy: 0.9531]
[Epoch 6/10] [Batch 234/235] [D loss: 0.3673] [G loss: 1.8452] [D accuracy: 0.9427]
[Epoch 7/10] [Batch 234/235] [D loss: 0.6838] [G loss: 4.4906] [D accuracy: 0.8385]
[Epoch 8/10] [Batch 234/235] [D loss: 0.1200] [G loss: 3.5295] [D accuracy: 0.9740]
[Epoch 9/10] [Batch 234/235] [D loss: 0.1374] [G loss: 3.7104] [D accuracy: 0.9583]
[Epoch 0/25] [Batch 234/235] [D loss: 0.0554] [G loss: 3.4267] [D accuracy: 0.9844]
[Epoch 1/25] [Batch 234/235] [D loss: 0.1394] [G loss: 3.4095] [D accuracy: 0.9740]
[Epoch 2/25] [Batch 234/235] [D loss: 0.0351] [G loss: 4.5743] [D accuracy: 0.9948]
[Epoch 3/25] [Batch 234/235] [D loss: 0.0444] [G loss: 4.3996] [D accuracy: 0.9844]
[Epoch 4/25] [Batch 234/235] [D loss: 0.1285] [G loss: 3.1817] [D accuracy: 0.9688]
[Epoch 5/25] [Batch 234/235] [D loss: 0.0521] [G loss: 6.0057] [D accuracy: 0.9844]
[Epoch 6/25] [Batch 234/235] [D loss: 0.0324] [G loss: 4.8753] [D accuracy: 0.9948]
[Epoch 7/25] [Batch 234/235] [D loss: 0.0895] [G loss: 5.0902] [D accuracy: 0.9792]
[Epoch 8/25] [Batch 234/235] [D loss: 0.0377] [G loss: 5.2114] [D accuracy: 0.9844]
[Epoch 9/25] [Batch 234/235] [D loss: 0.0387] [G loss: 6.4139] [D accuracy: 1.0000]
[Epoch 10/25] [Batch 234/235] [D loss: 0.0639] [G loss: 9.3777] [D accuracy: 0.9844]
[Epoch 11/25] [Batch 234/235] [D loss: 0.0055] [G loss: 6.6141] [D accuracy: 1.0000]
[Epoch 12/25] [Batch 234/235] [D loss: 0.0165] [G loss: 8.1812] [D accuracy: 1.0000]
[Epoch 13/25] [Batch 234/235] [D loss: 0.0770] [G loss: 8.8597] [D accuracy: 0.9792]
[Epoch 14/25] [Batch 234/235] [D loss: 0.0221] [G loss: 7.4139] [D accuracy: 0.9948]
[Epoch 15/25] [Batch 234/235] [D loss: 0.0184] [G loss: 6.3924] [D accuracy: 1.0000]
[Epoch 16/25] [Batch 234/235] [D loss: 0.0315] [G loss: 5.8193] [D accuracy: 0.9844]
[Epoch 17/25] [Batch 234/235] [D loss: 0.0294] [G loss: 5.0650] [D accuracy: 0.9948]
[Epoch 18/25] [Batch 234/235] [D loss: 0.0364] [G loss: 4.4933] [D accuracy: 0.9896]
[Epoch 19/25] [Batch 234/235] [D loss: 0.0640] [G loss: 4.6436] [D accuracy: 0.9896]
[Epoch 20/25] [Batch 234/235] [D loss: 0.0495] [G loss: 4.0981] [D accuracy: 1.0000]
[Epoch 21/25] [Batch 234/235] [D loss: 0.0513] [G loss: 7.1579] [D accuracy: 0.9792]
[Epoch 22/25] [Batch 234/235] [D loss: 0.1587] [G loss: 5.8698] [D accuracy: 0.9531]
[Epoch 23/25] [Batch 234/235] [D loss: 0.0933] [G loss: 4.9325] [D accuracy: 0.9688]
[Epoch 24/25] [Batch 234/235] [D loss: 0.0893] [G loss: 4.3482] [D accuracy: 0.9844]
Discriminator reached 100% accuracy!
[Epoch 0/25] [Batch 234/235] [D loss: 0.0740] [G loss: 4.3009] [D accuracy: 0.9688]
[Epoch 1/25] [Batch 234/235] [D loss: 0.1389] [G loss: 4.1182] [D accuracy: 0.9635]
[Epoch 2/25] [Batch 234/235] [D loss: 0.1427] [G loss: 2.6774] [D accuracy: 0.9740]
[Epoch 3/25] [Batch 234/235] [D loss: 0.0880] [G loss: 4.7401] [D accuracy: 0.9844]
[Epoch 4/25] [Batch 234/235] [D loss: 0.1643] [G loss: 4.3946] [D accuracy: 0.9583]
[Epoch 5/25] [Batch 234/235] [D loss: 0.0546] [G loss: 5.1011] [D accuracy: 0.9896]
[Epoch 6/25] [Batch 234/235] [D loss: 0.0948] [G loss: 4.5501] [D accuracy: 0.9635]
[Epoch 7/25] [Batch 234/235] [D loss: 0.1937] [G loss: 4.2976] [D accuracy: 0.9635]
[Epoch 8/25] [Batch 234/235] [D loss: 0.1356] [G loss: 5.0016] [D accuracy: 0.9635]
[Epoch 9/25] [Batch 234/235] [D loss: 0.1323] [G loss: 2.5699] [D accuracy: 0.9792]
[Epoch 10/25] [Batch 234/235] [D loss: 0.1010] [G loss: 4.5526] [D accuracy: 0.9531]
[Epoch 11/25] [Batch 234/235] [D loss: 0.1968] [G loss: 2.6433] [D accuracy: 0.9583]
[Epoch 12/25] [Batch 234/235] [D loss: 0.1258] [G loss: 3.6148] [D accuracy: 0.9688]
[Epoch 13/25] [Batch 234/235] [D loss: 0.1272] [G loss: 3.7790] [D accuracy: 0.9740]
[Epoch 14/25] [Batch 234/235] [D loss: 0.1387] [G loss: 3.3851] [D accuracy: 0.9635]
[Epoch 15/25] [Batch 234/235] [D loss: 0.1169] [G loss: 2.9182] [D accuracy: 0.9792]
[Epoch 16/25] [Batch 234/235] [D loss: 0.0657] [G loss: 3.5135] [D accuracy: 0.9948]
[Epoch 17/25] [Batch 234/235] [D loss: 0.0876] [G loss: 3.9413] [D accuracy: 0.9844]
[Epoch 18/25] [Batch 234/235] [D loss: 0.0662] [G loss: 4.3205] [D accuracy: 0.9896]
[Epoch 19/25] [Batch 234/235] [D loss: 0.0730] [G loss: 3.8728] [D accuracy: 0.9896]
[Epoch 20/25] [Batch 234/235] [D loss: 0.1064] [G loss: 2.9725] [D accuracy: 0.9948]
[Epoch 21/25] [Batch 234/235] [D loss: 0.0971] [G loss: 4.6962] [D accuracy: 0.9792]
[Epoch 22/25] [Batch 234/235] [D loss: 0.0784] [G loss: 4.1093] [D accuracy: 0.9844]
[Epoch 23/25] [Batch 234/235] [D loss: 0.1202] [G loss: 3.8507] [D accuracy: 0.9792]
[Epoch 24/25] [Batch 234/235] [D loss: 0.0962] [G loss: 4.6634] [D accuracy: 0.9844]
</pre></div>
</div>
<img alt="../_images/7ade76ce75af5fb33aa84b44fed8cd0455d3ee4d549c281f2512f93356b7e9cb.png" src="../_images/7ade76ce75af5fb33aa84b44fed8cd0455d3ee4d549c281f2512f93356b7e9cb.png" />
<img alt="../_images/c23f86e02cc86c303e0edbff4dc786965240f74d62506e938721f35f03c5a353.png" src="../_images/c23f86e02cc86c303e0edbff4dc786965240f74d62506e938721f35f03c5a353.png" />
</div>
</div>
</section>
<section id="implement-wgan-with-weight-clipping-strategy-and-wgan-gp-gradient-penalty-with-cifar-10-dataset-plot-the-generator-loss-and-discriminator-loss-w-r-t-epochs">
<h3>3. Implement WGAN (with weight clipping strategy) and WGAN-GP (Gradient penalty) with Cifar-10 dataset. Plot the generator loss and discriminator loss w.r.t epochs.<a class="headerlink" href="#implement-wgan-with-weight-clipping-strategy-and-wgan-gp-gradient-penalty-with-cifar-10-dataset-plot-the-generator-loss-and-discriminator-loss-w-r-t-epochs" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils</span> <span class="kn">import</span> <span class="n">spectral_norm</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># Hyperparameters</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">image_channels</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">image_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2048</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0002</span> 
<span class="n">weight_clip</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">n_critic</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">lambda_gp</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.5</span><span class="p">]</span><span class="o">*</span><span class="n">image_channels</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">]</span><span class="o">*</span><span class="n">image_channels</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;cifar&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">image_channels</span> <span class="o">*</span> <span class="n">image_size</span> <span class="o">*</span> <span class="n">image_size</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">image_channels</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_sn</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">use_sn</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_channels</span> <span class="o">*</span> <span class="n">image_size</span> <span class="o">*</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">)),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
                <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
                <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_channels</span> <span class="o">*</span> <span class="n">image_size</span> <span class="o">*</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="n">img_flat</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">validity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">img_flat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">validity</span>

<span class="k">def</span> <span class="nf">gradient_penalty</span><span class="p">(</span><span class="n">discriminator</span><span class="p">,</span> <span class="n">real_imgs</span><span class="p">,</span> <span class="n">fake_imgs</span><span class="p">):</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">real_imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">interpolates</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">real_imgs</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">fake_imgs</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">d_interpolates</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">interpolates</span><span class="p">)</span>
    <span class="n">fake</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">real_imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">gradients</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
        <span class="n">outputs</span><span class="o">=</span><span class="n">d_interpolates</span><span class="p">,</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">interpolates</span><span class="p">,</span>
        <span class="n">grad_outputs</span><span class="o">=</span><span class="n">fake</span><span class="p">,</span>
        <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">only_inputs</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">gradients</span> <span class="o">=</span> <span class="n">gradients</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">gradients</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">gradient_penalty</span> <span class="o">=</span> <span class="p">((</span><span class="n">gradients</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">gradient_penalty</span>

<span class="k">def</span> <span class="nf">train_gan</span><span class="p">(</span><span class="n">gan_type</span><span class="o">=</span><span class="s2">&quot;wgan&quot;</span><span class="p">):</span>
    <span class="n">generator</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">discriminator</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">use_sn</span><span class="o">=</span><span class="p">(</span><span class="n">gan_type</span><span class="o">==</span><span class="s2">&quot;sngan&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;sngan&quot;</span><span class="p">:</span>
        <span class="n">optimizer_G</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">))</span>
        <span class="n">optimizer_D</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">))</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">optimizer_G</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="n">optimizer_D</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="n">G_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">D_losses</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
            <span class="n">real_imgs</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">real_imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_critic</span><span class="p">):</span>
                <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">fake_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;wgan&quot;</span><span class="p">:</span>
                    <span class="n">loss_D</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">))</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">fake_imgs</span><span class="p">))</span>
                <span class="k">elif</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;wgan-gp&quot;</span><span class="p">:</span>
                    <span class="n">real_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">)</span>
                    <span class="n">fake_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">fake_imgs</span><span class="p">)</span>
                    <span class="n">gp</span> <span class="o">=</span> <span class="n">gradient_penalty</span><span class="p">(</span><span class="n">discriminator</span><span class="p">,</span> <span class="n">real_imgs</span><span class="p">,</span> <span class="n">fake_imgs</span><span class="p">)</span>
                    <span class="n">loss_D</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">real_validity</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">)</span> <span class="o">+</span> <span class="n">lambda_gp</span> <span class="o">*</span> <span class="n">gp</span>
                <span class="k">else</span><span class="p">:</span> 
                    <span class="n">real_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">)</span>
                    <span class="n">fake_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">fake_imgs</span><span class="p">)</span>
                    <span class="n">loss_real</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">real_validity</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">real_validity</span><span class="p">))</span>
                    <span class="n">loss_fake</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">))</span>
                    <span class="n">loss_D</span> <span class="o">=</span> <span class="n">loss_real</span> <span class="o">+</span> <span class="n">loss_fake</span>

                <span class="n">optimizer_D</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss_D</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer_D</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;wgan&quot;</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                        <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="o">-</span><span class="n">weight_clip</span><span class="p">,</span> <span class="n">weight_clip</span><span class="p">)</span>

            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">gen_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;sngan&quot;</span><span class="p">:</span>
                <span class="n">fake_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">)</span>
                <span class="n">loss_G</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss_G</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">))</span>

            <span class="n">optimizer_G</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss_G</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer_G</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">G_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_G</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">D_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_D</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">gan_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2">] [Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">] [D loss: </span><span class="si">{</span><span class="n">loss_D</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">] [G loss: </span><span class="si">{</span><span class="n">loss_G</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">G_losses</span><span class="p">,</span> <span class="n">D_losses</span>

<span class="c1"># Train WGAN</span>
<span class="n">wgan_G_losses</span><span class="p">,</span> <span class="n">wgan_D_losses</span> <span class="o">=</span> <span class="n">train_gan</span><span class="p">(</span><span class="s2">&quot;wgan&quot;</span><span class="p">)</span>

<span class="c1"># Train WGAN-GP</span>
<span class="n">wgan_gp_G_losses</span><span class="p">,</span> <span class="n">wgan_gp_D_losses</span> <span class="o">=</span> <span class="n">train_gan</span><span class="p">(</span><span class="s2">&quot;wgan-gp&quot;</span><span class="p">)</span>

<span class="c1"># Plot losses</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">wgan_G_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;G Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">wgan_D_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;D Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;WGAN Losses&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Iterations&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">wgan_gp_G_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;G Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">wgan_gp_D_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;D Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;WGAN-GP Losses&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Iterations&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Files already downloaded and verified
[WGAN] [Epoch 1/20] [D loss: -1.8016] [G loss: 3.6559]
[WGAN] [Epoch 2/20] [D loss: 0.4569] [G loss: 6.5473]
[WGAN] [Epoch 3/20] [D loss: -6.8577] [G loss: -3.6527]
[WGAN] [Epoch 4/20] [D loss: -8.8208] [G loss: 18.6705]
[WGAN] [Epoch 5/20] [D loss: -8.0744] [G loss: 1.0301]
[WGAN] [Epoch 6/20] [D loss: -4.9336] [G loss: 1.6088]
[WGAN] [Epoch 7/20] [D loss: -9.1072] [G loss: -1.8450]
[WGAN] [Epoch 8/20] [D loss: -9.3230] [G loss: 5.2087]
[WGAN] [Epoch 9/20] [D loss: -11.2970] [G loss: 8.5238]
[WGAN] [Epoch 10/20] [D loss: -8.2480] [G loss: 7.4013]
[WGAN] [Epoch 11/20] [D loss: -7.6190] [G loss: -2.0563]
[WGAN] [Epoch 12/20] [D loss: -10.8375] [G loss: 2.1927]
[WGAN] [Epoch 13/20] [D loss: -7.8534] [G loss: 5.5149]
[WGAN] [Epoch 14/20] [D loss: -5.5890] [G loss: 2.8620]
[WGAN] [Epoch 15/20] [D loss: -9.1929] [G loss: 1.4552]
[WGAN] [Epoch 16/20] [D loss: -8.9392] [G loss: -0.2418]
[WGAN] [Epoch 17/20] [D loss: -5.3524] [G loss: 0.5674]
[WGAN] [Epoch 18/20] [D loss: -7.3477] [G loss: 3.1088]
[WGAN] [Epoch 19/20] [D loss: -7.9845] [G loss: -0.3174]
[WGAN] [Epoch 20/20] [D loss: -7.0386] [G loss: -2.5900]
[WGAN-GP] [Epoch 1/20] [D loss: -9.9689] [G loss: 1.4156]
[WGAN-GP] [Epoch 2/20] [D loss: -9.3908] [G loss: -0.4003]
[WGAN-GP] [Epoch 3/20] [D loss: -7.4579] [G loss: -3.0720]
[WGAN-GP] [Epoch 4/20] [D loss: -6.9089] [G loss: -1.8922]
[WGAN-GP] [Epoch 5/20] [D loss: -6.6050] [G loss: -1.6074]
[WGAN-GP] [Epoch 6/20] [D loss: -6.0935] [G loss: -0.1799]
[WGAN-GP] [Epoch 7/20] [D loss: -5.8648] [G loss: -2.3666]
[WGAN-GP] [Epoch 8/20] [D loss: -6.0644] [G loss: -3.3392]
[WGAN-GP] [Epoch 9/20] [D loss: -5.7344] [G loss: -1.2663]
[WGAN-GP] [Epoch 10/20] [D loss: -5.6631] [G loss: 1.0956]
[WGAN-GP] [Epoch 11/20] [D loss: -5.7743] [G loss: -0.2332]
[WGAN-GP] [Epoch 12/20] [D loss: -5.4346] [G loss: -0.8496]
[WGAN-GP] [Epoch 13/20] [D loss: -6.1589] [G loss: 2.2150]
[WGAN-GP] [Epoch 14/20] [D loss: -5.5149] [G loss: 0.0024]
[WGAN-GP] [Epoch 15/20] [D loss: -5.1741] [G loss: -0.5459]
[WGAN-GP] [Epoch 16/20] [D loss: -5.2716] [G loss: -1.1355]
[WGAN-GP] [Epoch 17/20] [D loss: -5.5850] [G loss: 2.4683]
[WGAN-GP] [Epoch 18/20] [D loss: -5.0898] [G loss: -0.0771]
[WGAN-GP] [Epoch 19/20] [D loss: -5.2978] [G loss: -1.3626]
[WGAN-GP] [Epoch 20/20] [D loss: -5.4236] [G loss: 2.3668]
</pre></div>
</div>
<img alt="../_images/1759bd09bd9a7074bcf314ad444be16ac42feb2a6dc290f3c4b435d2b6d3e5d9.png" src="../_images/1759bd09bd9a7074bcf314ad444be16ac42feb2a6dc290f3c4b435d2b6d3e5d9.png" />
</div>
</div>
</section>
<section id="implement-sngan-framework-too-with-cifar-10-dataset">
<h3>4. Implement SNGAN framework too with Cifar-10 dataset.<a class="headerlink" href="#implement-sngan-framework-too-with-cifar-10-dataset" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils</span> <span class="kn">import</span> <span class="n">spectral_norm</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># Hyperparameters</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">image_channels</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">image_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2048</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0002</span> 
<span class="n">weight_clip</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">n_critic</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">lambda_gp</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.5</span><span class="p">]</span><span class="o">*</span><span class="n">image_channels</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">]</span><span class="o">*</span><span class="n">image_channels</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;cifar&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Generator</span>
<span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">image_channels</span> <span class="o">*</span> <span class="n">image_size</span> <span class="o">*</span> <span class="n">image_size</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">image_channels</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">)</span>

<span class="c1"># Discriminator</span>
<span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_sn</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">use_sn</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_channels</span> <span class="o">*</span> <span class="n">image_size</span> <span class="o">*</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">)),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
                <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
                <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_channels</span> <span class="o">*</span> <span class="n">image_size</span> <span class="o">*</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="n">img_flat</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">validity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">img_flat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">validity</span>

<span class="k">def</span> <span class="nf">gradient_penalty</span><span class="p">(</span><span class="n">discriminator</span><span class="p">,</span> <span class="n">real_imgs</span><span class="p">,</span> <span class="n">fake_imgs</span><span class="p">):</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">real_imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">interpolates</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">real_imgs</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">fake_imgs</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">d_interpolates</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">interpolates</span><span class="p">)</span>
    <span class="n">fake</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">real_imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">gradients</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
        <span class="n">outputs</span><span class="o">=</span><span class="n">d_interpolates</span><span class="p">,</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">interpolates</span><span class="p">,</span>
        <span class="n">grad_outputs</span><span class="o">=</span><span class="n">fake</span><span class="p">,</span>
        <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">only_inputs</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">gradients</span> <span class="o">=</span> <span class="n">gradients</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">gradients</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">gradient_penalty</span> <span class="o">=</span> <span class="p">((</span><span class="n">gradients</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">gradient_penalty</span>

<span class="k">def</span> <span class="nf">train_gan</span><span class="p">(</span><span class="n">gan_type</span><span class="o">=</span><span class="s2">&quot;wgan&quot;</span><span class="p">):</span>
    <span class="n">generator</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">discriminator</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">use_sn</span><span class="o">=</span><span class="p">(</span><span class="n">gan_type</span><span class="o">==</span><span class="s2">&quot;sngan&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;sngan&quot;</span><span class="p">:</span>
        <span class="n">optimizer_G</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">))</span>
        <span class="n">optimizer_D</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">))</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">optimizer_G</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="n">optimizer_D</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="n">G_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">D_losses</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
            <span class="n">real_imgs</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">real_imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># Train Discriminator</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_critic</span><span class="p">):</span>
                <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">fake_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;wgan&quot;</span><span class="p">:</span>
                    <span class="n">loss_D</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">))</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">fake_imgs</span><span class="p">))</span>
                <span class="k">elif</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;wgan-gp&quot;</span><span class="p">:</span>
                    <span class="n">real_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">)</span>
                    <span class="n">fake_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">fake_imgs</span><span class="p">)</span>
                    <span class="n">gp</span> <span class="o">=</span> <span class="n">gradient_penalty</span><span class="p">(</span><span class="n">discriminator</span><span class="p">,</span> <span class="n">real_imgs</span><span class="p">,</span> <span class="n">fake_imgs</span><span class="p">)</span>
                    <span class="n">loss_D</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">real_validity</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">)</span> <span class="o">+</span> <span class="n">lambda_gp</span> <span class="o">*</span> <span class="n">gp</span>
                <span class="k">else</span><span class="p">:</span>  <span class="c1"># SNGAN</span>
                    <span class="n">real_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">)</span>
                    <span class="n">fake_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">fake_imgs</span><span class="p">)</span>
                    <span class="n">loss_real</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">real_validity</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">real_validity</span><span class="p">))</span>
                    <span class="n">loss_fake</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">))</span>
                    <span class="n">loss_D</span> <span class="o">=</span> <span class="n">loss_real</span> <span class="o">+</span> <span class="n">loss_fake</span>

                <span class="n">optimizer_D</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss_D</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer_D</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;wgan&quot;</span><span class="p">:</span>
                    <span class="c1"># Weight clipping for original WGAN</span>
                    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                        <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="o">-</span><span class="n">weight_clip</span><span class="p">,</span> <span class="n">weight_clip</span><span class="p">)</span>

            <span class="c1"># Train Generator</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">gen_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;sngan&quot;</span><span class="p">:</span>
                <span class="n">fake_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">)</span>
                <span class="n">loss_G</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss_G</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">))</span>

            <span class="n">optimizer_G</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss_G</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer_G</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">G_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_G</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">D_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_D</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">gan_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2">] [Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">] [D loss: </span><span class="si">{</span><span class="n">loss_D</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">] [G loss: </span><span class="si">{</span><span class="n">loss_G</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">G_losses</span><span class="p">,</span> <span class="n">D_losses</span>

<span class="n">sngan_G_losses</span><span class="p">,</span> <span class="n">sngan_D_losses</span> <span class="o">=</span> <span class="n">train_gan</span><span class="p">(</span><span class="s2">&quot;sngan&quot;</span><span class="p">)</span>

<span class="c1"># Plot losses</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sngan_G_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;G Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sngan_D_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;D Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;SNGAN Losses&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Iterations&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Files already downloaded and verified
[SNGAN] [Epoch 1/20] [D loss: 0.1994] [G loss: 2.3422]
[SNGAN] [Epoch 2/20] [D loss: 0.3186] [G loss: 1.6344]
[SNGAN] [Epoch 3/20] [D loss: 0.4953] [G loss: 2.0589]
[SNGAN] [Epoch 4/20] [D loss: 0.5471] [G loss: 1.5974]
[SNGAN] [Epoch 5/20] [D loss: 0.5994] [G loss: 1.4895]
[SNGAN] [Epoch 6/20] [D loss: 0.8523] [G loss: 1.3101]
[SNGAN] [Epoch 7/20] [D loss: 0.7954] [G loss: 1.2098]
[SNGAN] [Epoch 8/20] [D loss: 0.8724] [G loss: 1.0855]
[SNGAN] [Epoch 9/20] [D loss: 0.9771] [G loss: 1.0815]
[SNGAN] [Epoch 10/20] [D loss: 0.8760] [G loss: 1.2004]
[SNGAN] [Epoch 11/20] [D loss: 0.8820] [G loss: 1.0571]
[SNGAN] [Epoch 12/20] [D loss: 0.8847] [G loss: 1.0727]
[SNGAN] [Epoch 13/20] [D loss: 0.9425] [G loss: 1.0759]
[SNGAN] [Epoch 14/20] [D loss: 0.9560] [G loss: 1.0255]
[SNGAN] [Epoch 15/20] [D loss: 0.9511] [G loss: 1.0550]
[SNGAN] [Epoch 16/20] [D loss: 0.9042] [G loss: 1.2685]
[SNGAN] [Epoch 17/20] [D loss: 0.9459] [G loss: 0.9778]
[SNGAN] [Epoch 18/20] [D loss: 1.0134] [G loss: 1.0354]
[SNGAN] [Epoch 19/20] [D loss: 1.0256] [G loss: 0.9897]
[SNGAN] [Epoch 20/20] [D loss: 1.0261] [G loss: 1.0060]
</pre></div>
</div>
<img alt="../_images/52d3c91add0c00cd24e117458e9fcd7647c6ac9b6d7d47a69da917f7ccf17d5b.png" src="../_images/52d3c91add0c00cd24e117458e9fcd7647c6ac9b6d7d47a69da917f7ccf17d5b.png" />
</div>
</div>
</section>
<section id="observe-and-compare-the-time-complexity-of-sn-gan-and-wgan-gp">
<h3>5. Observe and Compare the time complexity of SN-GAN and WGAN-GP.<a class="headerlink" href="#observe-and-compare-the-time-complexity-of-sn-gan-and-wgan-gp" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils</span> <span class="kn">import</span> <span class="n">spectral_norm</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># Hyperparameters</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">image_channels</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">image_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8192</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0002</span>  
<span class="n">weight_clip</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">n_critic</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">lambda_gp</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># CIFAR-10 Dataset</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.5</span><span class="p">]</span><span class="o">*</span><span class="n">image_channels</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">]</span><span class="o">*</span><span class="n">image_channels</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Generator</span>
<span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">image_channels</span> <span class="o">*</span> <span class="n">image_size</span> <span class="o">*</span> <span class="n">image_size</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">image_channels</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">)</span>

<span class="c1"># Discriminator</span>
<span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_sn</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">use_sn</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_channels</span> <span class="o">*</span> <span class="n">image_size</span> <span class="o">*</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">)),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
                <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
                <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_channels</span> <span class="o">*</span> <span class="n">image_size</span> <span class="o">*</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="n">img_flat</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">validity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">img_flat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">validity</span>

<span class="c1"># Gradient penalty function for WGAN-GP</span>
<span class="k">def</span> <span class="nf">gradient_penalty</span><span class="p">(</span><span class="n">discriminator</span><span class="p">,</span> <span class="n">real_imgs</span><span class="p">,</span> <span class="n">fake_imgs</span><span class="p">):</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">real_imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">interpolates</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">real_imgs</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">fake_imgs</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">d_interpolates</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">interpolates</span><span class="p">)</span>
    <span class="n">fake</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">real_imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">gradients</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
        <span class="n">outputs</span><span class="o">=</span><span class="n">d_interpolates</span><span class="p">,</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">interpolates</span><span class="p">,</span>
        <span class="n">grad_outputs</span><span class="o">=</span><span class="n">fake</span><span class="p">,</span>
        <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">only_inputs</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">gradients</span> <span class="o">=</span> <span class="n">gradients</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">gradients</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">gradient_penalty</span> <span class="o">=</span> <span class="p">((</span><span class="n">gradients</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">gradient_penalty</span>

<span class="k">def</span> <span class="nf">train_gan</span><span class="p">(</span><span class="n">gan_type</span><span class="o">=</span><span class="s2">&quot;wgan&quot;</span><span class="p">):</span>
    <span class="n">generator</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">discriminator</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">use_sn</span><span class="o">=</span><span class="p">(</span><span class="n">gan_type</span><span class="o">==</span><span class="s2">&quot;sngan&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;sngan&quot;</span><span class="p">:</span>
        <span class="n">optimizer_G</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">))</span>
        <span class="n">optimizer_D</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">))</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">optimizer_G</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="n">optimizer_D</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="n">G_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">D_losses</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> 

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
            <span class="n">real_imgs</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">real_imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># Train Discriminator</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_critic</span><span class="p">):</span>
                <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">fake_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;wgan&quot;</span><span class="p">:</span>
                    <span class="n">loss_D</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">))</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">fake_imgs</span><span class="p">))</span>
                <span class="k">elif</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;wgan-gp&quot;</span><span class="p">:</span>
                    <span class="n">real_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">)</span>
                    <span class="n">fake_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">fake_imgs</span><span class="p">)</span>
                    <span class="n">gp</span> <span class="o">=</span> <span class="n">gradient_penalty</span><span class="p">(</span><span class="n">discriminator</span><span class="p">,</span> <span class="n">real_imgs</span><span class="p">,</span> <span class="n">fake_imgs</span><span class="p">)</span>
                    <span class="n">loss_D</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">real_validity</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">)</span> <span class="o">+</span> <span class="n">lambda_gp</span> <span class="o">*</span> <span class="n">gp</span>
                <span class="k">else</span><span class="p">:</span> 
                    <span class="n">real_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">)</span>
                    <span class="n">fake_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">fake_imgs</span><span class="p">)</span>
                    <span class="n">loss_real</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">real_validity</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">real_validity</span><span class="p">))</span>
                    <span class="n">loss_fake</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">))</span>
                    <span class="n">loss_D</span> <span class="o">=</span> <span class="n">loss_real</span> <span class="o">+</span> <span class="n">loss_fake</span>

                <span class="n">optimizer_D</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss_D</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer_D</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;wgan&quot;</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                        <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="o">-</span><span class="n">weight_clip</span><span class="p">,</span> <span class="n">weight_clip</span><span class="p">)</span>

            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">gen_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">gan_type</span> <span class="o">==</span> <span class="s2">&quot;sngan&quot;</span><span class="p">:</span>
                <span class="n">fake_validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">)</span>
                <span class="n">loss_G</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">fake_validity</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss_G</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">))</span>

            <span class="n">optimizer_G</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss_G</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer_G</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">G_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_G</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">D_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_D</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">gan_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2">] [Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">] [D loss: </span><span class="si">{</span><span class="n">loss_D</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">] [G loss: </span><span class="si">{</span><span class="n">loss_G</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

    <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  
    <span class="n">total_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># Calculate total time</span>

    <span class="k">return</span> <span class="n">G_losses</span><span class="p">,</span> <span class="n">D_losses</span><span class="p">,</span> <span class="n">total_time</span><span class="p">,</span> <span class="n">generator</span>

<span class="c1"># Train WGAN</span>
<span class="n">wgan_G_losses</span><span class="p">,</span> <span class="n">wgan_D_losses</span><span class="p">,</span> <span class="n">wgan_time</span><span class="p">,</span> <span class="n">wgan_generator</span> <span class="o">=</span> <span class="n">train_gan</span><span class="p">(</span><span class="s2">&quot;wgan&quot;</span><span class="p">)</span>

<span class="c1"># Train WGAN-GP</span>
<span class="n">wgan_gp_G_losses</span><span class="p">,</span> <span class="n">wgan_gp_D_losses</span><span class="p">,</span> <span class="n">wgan_gp_time</span><span class="p">,</span> <span class="n">wgan_gp_generator</span> <span class="o">=</span> <span class="n">train_gan</span><span class="p">(</span><span class="s2">&quot;wgan-gp&quot;</span><span class="p">)</span>

<span class="c1"># Train SNGAN</span>
<span class="n">sngan_G_losses</span><span class="p">,</span> <span class="n">sngan_D_losses</span><span class="p">,</span> <span class="n">sngan_time</span><span class="p">,</span> <span class="n">sngan_generator</span> <span class="o">=</span> <span class="n">train_gan</span><span class="p">(</span><span class="s2">&quot;sngan&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WGAN time: </span><span class="si">{</span><span class="n">wgan_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WGAN-GP time: </span><span class="si">{</span><span class="n">wgan_gp_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SNGAN time: </span><span class="si">{</span><span class="n">sngan_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Files already downloaded and verified
[WGAN] [Epoch 1/10] [D loss: -31.4903] [G loss: 11.6564]
[WGAN] [Epoch 2/10] [D loss: -65.0461] [G loss: 10.0199]
[WGAN] [Epoch 3/10] [D loss: -59.7032] [G loss: 76.3978]
[WGAN] [Epoch 4/10] [D loss: -11.6625] [G loss: -0.8076]
[WGAN] [Epoch 5/10] [D loss: -68.8848] [G loss: 6.9758]
[WGAN] [Epoch 6/10] [D loss: 48.8451] [G loss: -85.0976]
[WGAN] [Epoch 7/10] [D loss: -35.1861] [G loss: 59.3865]
[WGAN] [Epoch 8/10] [D loss: 22.4874] [G loss: -0.1850]
[WGAN] [Epoch 9/10] [D loss: -46.6324] [G loss: 0.6300]
[WGAN] [Epoch 10/10] [D loss: 40.1227] [G loss: -52.0626]
[WGAN-GP] [Epoch 1/10] [D loss: -16.4519] [G loss: 4.2048]
[WGAN-GP] [Epoch 2/10] [D loss: -8.8388] [G loss: 2.4366]
[WGAN-GP] [Epoch 3/10] [D loss: -9.5875] [G loss: 2.6280]
[WGAN-GP] [Epoch 4/10] [D loss: -10.4272] [G loss: 1.6363]
[WGAN-GP] [Epoch 5/10] [D loss: -9.8339] [G loss: -2.5116]
[WGAN-GP] [Epoch 6/10] [D loss: -9.0357] [G loss: -2.8978]
[WGAN-GP] [Epoch 7/10] [D loss: -8.6146] [G loss: -3.1273]
[WGAN-GP] [Epoch 8/10] [D loss: -9.0200] [G loss: 1.4725]
[WGAN-GP] [Epoch 9/10] [D loss: -8.5530] [G loss: -2.8941]
[WGAN-GP] [Epoch 10/10] [D loss: -8.1438] [G loss: -1.0001]
[SNGAN] [Epoch 1/10] [D loss: 0.2101] [G loss: 2.7418]
[SNGAN] [Epoch 2/10] [D loss: 0.2638] [G loss: 2.0203]
[SNGAN] [Epoch 3/10] [D loss: 0.2483] [G loss: 2.3963]
[SNGAN] [Epoch 4/10] [D loss: 0.2584] [G loss: 2.3527]
[SNGAN] [Epoch 5/10] [D loss: 0.3052] [G loss: 1.9890]
[SNGAN] [Epoch 6/10] [D loss: 0.4130] [G loss: 2.2281]
[SNGAN] [Epoch 7/10] [D loss: 0.2278] [G loss: 2.1226]
[SNGAN] [Epoch 8/10] [D loss: 0.6234] [G loss: 1.9509]
[SNGAN] [Epoch 9/10] [D loss: 0.6776] [G loss: 1.9879]
[SNGAN] [Epoch 10/10] [D loss: 0.3982] [G loss: 1.1956]
WGAN time: 151.63 seconds
WGAN-GP time: 167.11 seconds
SNGAN time: 141.76 seconds
</pre></div>
</div>
</div>
</div>
</section>
<section id="use-inception-score-and-fid-scores-to-evaluate-models-trained-in-previous-questions">
<h3>6. Use Inception score and FID scores to evaluate models trained in previous questions.<a class="headerlink" href="#use-inception-score-and-fid-scores-to-evaluate-models-trained-in-previous-questions" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torchvision.utils</span> <span class="k">as</span> <span class="nn">vutils</span>
<span class="kn">from</span> <span class="nn">torch_fidelity</span> <span class="kn">import</span> <span class="n">calculate_metrics</span>
<span class="kn">from</span> <span class="nn">pytorch_image_generation_metrics</span> <span class="kn">import</span> <span class="n">get_inception_score</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="c1"># Helper function to save images to a temporary directory</span>
<span class="k">def</span> <span class="nf">save_images_to_dir</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">directory</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">img</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">images</span><span class="p">):</span>
        <span class="n">img_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;img_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">)</span>
        <span class="n">vutils</span><span class="o">.</span><span class="n">save_image</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">img_path</span><span class="p">)</span>

<span class="c1"># Function to calculate FID score and Inception score</span>
<span class="k">def</span> <span class="nf">evaluate_gan</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="n">real_images_dir</span><span class="o">=</span><span class="s2">&quot;real_images&quot;</span><span class="p">,</span> <span class="n">fake_images_dir</span><span class="o">=</span><span class="s2">&quot;fake_images&quot;</span><span class="p">):</span>
    <span class="n">generator</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="n">real_imgs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">fake_imgs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">num_images</span> <span class="o">=</span> <span class="mi">1000</span> 
    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
            <span class="n">real_imgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">&gt;=</span> <span class="n">num_images</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="n">fake_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="n">real_imgs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">)[:</span><span class="n">num_images</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
    <span class="n">fake_imgs</span> <span class="o">=</span> <span class="n">fake_imgs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

    <span class="n">save_images_to_dir</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">,</span> <span class="n">real_images_dir</span><span class="p">)</span>
    <span class="n">save_images_to_dir</span><span class="p">(</span><span class="n">fake_imgs</span><span class="p">,</span> <span class="n">fake_images_dir</span><span class="p">)</span>

    <span class="n">metrics</span> <span class="o">=</span> <span class="n">calculate_metrics</span><span class="p">(</span><span class="n">input1</span><span class="o">=</span><span class="n">real_images_dir</span><span class="p">,</span> <span class="n">input2</span><span class="o">=</span><span class="n">fake_images_dir</span><span class="p">,</span> <span class="n">fid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">inception_score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_inception_score</span><span class="p">(</span><span class="n">fake_imgs</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FID Score: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;frechet_inception_distance&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inception Score: </span><span class="si">{</span><span class="n">inception_score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Evaluate WGAN</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;WGAN Evaluations:&#39;</span><span class="p">)</span>
<span class="n">evaluate_gan</span><span class="p">(</span><span class="n">wgan_generator</span><span class="p">,</span> <span class="n">real_images_dir</span><span class="o">=</span><span class="s2">&quot;real_images_wgan&quot;</span><span class="p">,</span> <span class="n">fake_images_dir</span><span class="o">=</span><span class="s2">&quot;fake_images_wgan&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="c1"># Evaluate WGAN-GP</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;WGAN-GP Evaluations:&#39;</span><span class="p">)</span>
<span class="n">evaluate_gan</span><span class="p">(</span><span class="n">wgan_gp_generator</span><span class="p">,</span> <span class="n">real_images_dir</span><span class="o">=</span><span class="s2">&quot;real_images_wgan_gp&quot;</span><span class="p">,</span> <span class="n">fake_images_dir</span><span class="o">=</span><span class="s2">&quot;fake_images_wgan_gp&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="c1"># Evaluate SNGAN</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;SNGAN Evaluations:&#39;</span><span class="p">)</span>
<span class="n">evaluate_gan</span><span class="p">(</span><span class="n">sngan_generator</span><span class="p">,</span> <span class="n">real_images_dir</span><span class="o">=</span><span class="s2">&quot;real_images_sngan&quot;</span><span class="p">,</span> <span class="n">fake_images_dir</span><span class="o">=</span><span class="s2">&quot;fake_images_sngan&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WGAN Evaluations:
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Exception ignored in: &lt;function _MultiProcessingDataLoaderIter.__del__ at 0x7da94422f640&gt;
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py&quot;, line 1477, in __del__
    self._shutdown_workers()
  File &quot;/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py&quot;, line 1460, in _shutdown_workers
    if w.is_alive():
  File &quot;/usr/lib/python3.10/multiprocessing/process.py&quot;, line 160, in is_alive
    assert self._parent_pid == os.getpid(), &#39;can only test a child process&#39;
AssertionError: can only test a child process
Exception ignored in: &lt;function _MultiProcessingDataLoaderIter.__del__ at 0x7da94422f640&gt;
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py&quot;, line 1477, in __del__
    self._shutdown_workers()
  File &quot;/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py&quot;, line 1460, in _shutdown_workers
    if w.is_alive():
  File &quot;/usr/lib/python3.10/multiprocessing/process.py&quot;, line 160, in is_alive
assert self._parent_pid == os.getpid(), &#39;can only test a child process&#39;    
AssertionError: can only test a child process
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>FID Score: 371.7746169920233
Inception Score: 1.722624498927651

WGAN-GP Evaluations:
FID Score: 216.85007760795895
Inception Score: 2.0898751729173317

SNGAN Evaluations:
FID Score: 323.4748607033323
Inception Score: 1.404180479441253
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./genai"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../experiences.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Education &amp; Experiences</p>
      </div>
    </a>
    <a class="right-next"
       href="../Databases.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Database</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Generative Models</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-vae-on-mnist-dataset">Implement VAE on MNIST dataset</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#programming-use-pytorch-tf-library">2 Programming - Use Pytorch/TF library</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-autoencoder">2.1 Variational Autoencoder</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-basic-vae-on-celeba-faces-dataset">1. Implement basic VAE on celebA faces dataset.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#latent-space-arithmetic-make-your-image-smile-generate-smiling-face-images-by-playing-with-latent-space-z-vector">2. Latent Space arithmetic - Make your image smile. Generate smiling face images by playing with latent space z vector.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variants-of-gans">2.2 Variants of GANs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-a-standard-gan-on-mnist-cifar-10-data-plot-generator-loss-discriminator-loss-and-classification-accuracy-of-discriminator-with-respect-to-iterations">1. Implement a standard GAN on MNIST/CIFAR-10 data. Plot Generator loss, Discriminator Loss and Classification accuracy of discriminator with respect to iterations.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstrate-the-vanishing-gradient-problem-of-standard-gan-by-training-your-gan-for-5-10-and-25-epochs-then-stop-the-gan-training-train-only-the-discriminator-till-it-reaches-100-accuracy-and-then-use-this-perfect-discriminator-to-train-your-gan-plot-the-generator-loss-gradient-norm-and-discriminator-loss-w-r-t-epochs-using-your-perfect-discriminator">2. Demonstrate the vanishing gradient problem of standard GAN by training your GAN for 5,10 and 25 epochs. Then stop the GAN training, train only the discriminator till it reaches 100% accuracy and then use this perfect discriminator to train your GAN. Plot the generator loss/gradient norm and discriminator loss w.r.t epochs (using your perfect discriminator).</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-wgan-with-weight-clipping-strategy-and-wgan-gp-gradient-penalty-with-cifar-10-dataset-plot-the-generator-loss-and-discriminator-loss-w-r-t-epochs">3. Implement WGAN (with weight clipping strategy) and WGAN-GP (Gradient penalty) with Cifar-10 dataset. Plot the generator loss and discriminator loss w.r.t epochs.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-sngan-framework-too-with-cifar-10-dataset">4. Implement SNGAN framework too with Cifar-10 dataset.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#observe-and-compare-the-time-complexity-of-sn-gan-and-wgan-gp">5. Observe and Compare the time complexity of SN-GAN and WGAN-GP.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-inception-score-and-fid-scores-to-evaluate-models-trained-in-previous-questions">6. Use Inception score and FID scores to evaluate models trained in previous questions.</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Shivesh
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>